---
title: "INE"
author: "João Dionísio"
date: "February 2023"
format:
  html:
    smooth-scroll: true
    self-contained: true
    toc: true
    toc-location: left
theme: cosmo
smooth-scroll: true
execute:
  warning: false
project:
  output-dir: outputs/documents
---

## Packages

```{r, include=FALSE}
#install.packages('jsonlite', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(jsonlite)

#install.packages("tidyverse", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(tidyverse)

locale("pt")
# install.packages("readxl", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(readxl)

# install.packages("data.table")
library(data.table)

# install.packages("shiny")
library(shiny)
```

## Fetch Datasets

All datasets from INE - Bulky - still needs works

Passos para extração em código:

1.  Extração dos indicadores do INE

2.  Filtro para os que estão disponíveis do portal

3.  Destes o ideal será escolher alguns e filtrar por esses - ainda não implementado

4.  Depois teremos duas opções:

    1.  Extração do último ano ou últimos anos com todos os dados- ainda não implementado

        1.  Limitações de linhas

    2.  Extração por municipios ou áreas desejadas - ver Dim

```{r, include=FALSE}
library(readxl)
Indicadores <- read_excel("INE_API/datasets/Indicadores.xlsx", skip = 14)

Indicadores <- Indicadores %>%
  filter(`Disponível no Portal`== "Sim")
, ordered= TRUE

graph_test <- X0008639 %>%
  # filter(aces2=="ACeS Baixo Mondego")%>%
  mutate(valor = as.numeric(valor))%>%
  mutate(year = str_sub(obs,-4))%>%
  arrange(obs, year)

if(any(str_detect(colnames(graph_test), "dim"))){
          graph_test <- graph_test%>%
            select(ends_with("t")|!starts_with("dim"))
}

graph_test 

graph_test <- graph_test%>% 
 mutate(test = interaction(dim_4_t, dim_3_t, sep = ", "))%>%
 summarise(valor= sum(valor, na.rm = TRUE), .by = c(obs,test,geodsg, year))
 
graph_test

Ideia 1 

ggplot2::ggplot() +
                # This line adds a line layer with 'obs' on the x-axis, 'valor' on the y-axis, 'geodsg' as color, and 'geodsg' as the grouping variable
                geom_line(data = graph_test,
                          aes(x = factor(obs, levels = unique(obs), ordered = TRUE),
                              y = valor,
                              colour = test)
                              ,linewidth = 1.2) +
                facet_wrap(~geodsg, scales = "free")+
                # This line rotates the x-axis labels by 90 degrees
                scale_x_discrete(guide = guide_axis(angle = 90)) +
                # This line adds a legend for the color variable, using the name 'Localização Geográfica'
                scale_color_discrete(name = "Localização Geográfica e 3ª dimensão")+
                coord_cartesian(expand = FALSE)+
                labs(
                  x = "Observações",
                  y = "Valor",
                  title = "Teste",
                  caption = "Fonte dos Dados:INE",
                  # color = "Localização Geográfica"
                ) +
                theme_minimal()

2 ideia

 data1<- data1%>% 
              mutate(aggregate = interaction(geodsg, dim_3_t, sep = ", "))%>%
              summarise(valor= sum(valor, na.rm = TRUE), .by = c(obs,aggregate,geodsg,dim_3_t,year))%>%
              arrange(obs, year)
            
            
            p <- ggplot2::ggplot() +
              # This line adds a line layer with 'obs' on the x-axis, 'valor' on the y-axis, 'geodsg' as color, and 'geodsg' as the grouping variable
              geom_line(data = data1,
                        aes(x = factor(obs, levels = unique(obs), ordered = TRUE),
                            y = valor,
                            colour = dim_3_t,
                            group = aggregate),
                        linewidth = 1.2) +
              facet_wrap(~geodsg, scales = "free")+
              # This line rotates the x-axis labels by 90 degrees
              scale_x_discrete(guide = guide_axis(angle = 90)) +
              # This line adds a legend for the color variable, using the name 'Localização Geográfica'
              scale_color_hue(name = "Localização Geográfica") +
              scale_color_hue(direction=1, aesthetics = "group")+
              # This line sets the chart limits to remove extra white space
              coord_cartesian(expand = FALSE) +
              # This line adds a chart title, subtitle, and caption
              labs(x = "Observações",
                   y = "Valor",
                   title = full_name,
                   subtitle = paste0("Últimas ", length(unique(data1$obs)), " Observações"),
                   caption = "Fonte dos Dados: INE") +
              # This line sets the chart style to minimal and customizes the font sizes
              theme_minimal() +
              theme(plot.title = element_text(size = 14, face = "bold"),
                    plot.subtitle = element_text(size = 12, face = "bold"),
                    axis.title.y = element_text(size = 12),
                    axis.title.x = element_text(size = 12),
                    axis.text.y = element_text(size = 12),
                    axis.text.x = element_text(size = 12),
                    legend.title = element_text(size = 12))

# ggplot() +
#   geom_line(data = graph_test, aes(x = factor(year, levels=unique(year),ordered= TRUE),y = as.numeric(valor), colour = geodsg test), linewidth = 1.2) +
#   scale_x_discrete(guide = guide_axis(angle = 90))+
#   # scale_color_discrete(name = "Localização Geográfica") +
#   scale_color_hue(direction=1, aesthetics = "colour")+


# length(unique(graph_test$year))
```

Exemplo Simples de como funciona a app

```{r, eval=FALSE}
```


```{r, eval=FALSE}
```


```{r, eval=FALSE}
```


```{r, eval=FALSE}
```


```{r, eval=FALSE}
```


```{r, eval=FALSE}
#| code-fold: true
#| code-summary: "Mostrar Código"
# https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0011613&Dim1=T&lang=PT
meta_list <- list()
indicators <- c("0008614","0009817")
sleep <- function(z) {
  if (z %% 100 == 0) {
    Sys.sleep(5)
    z <- 1
  } else {
    z <- z + 1
  }
  return(z)
}
df3 <- list()
df3[[1]] <- data.frame()
if(!"valor" %in% colnames(df3[[1]])){
       df3[[1]] <- data.frame(geocod=0, geodsg=0, valor=0,obs=0, year=0)
      }
df3 <- data.frame(geocod=0, geodsg=0, valor=0,obs=0, year=0)

results_raw <-
              fromJSON(
                paste0(
                  "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
                  "0008460",
                  "&Dim1=T",
                  "&Dim2=",
                  "PT",
                  "&lang=PT"
                )
              )

results_raw1 <-
              fromJSON(
                paste0(
                  "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
                  "0008460",
                  "&Dim1=T",
                  "",
                  "",
                  "&lang=PT"
                )
              )

results_raw <- fromJSON(
      paste0(
        "https://www.ine.pt/ine/json_indicador/pindicaMeta.jsp?varcd=",
        "0008614",
        "&lang=PT"
      ))

names(model_arima)
ine.meta(indicators, meta_list)

ine.meta <- function(indicators, meta_list){
  counter <- 0
  for (i in 1:length(indicators)) {
    # Get the current indicator
    counter <- sleep(counter)
    indicators_current <- indicators[i]
    # Call the sleep function
    counter <- sleep(counter)
    # meta_list[[descricao]]
    results_raw <- fromJSON(
      paste0(
        "https://www.ine.pt/ine/json_indicador/pindicaMeta.jsp?varcd=",
        indicators_current,
        "&lang=PT"
      ))
    names <- results_raw %>% select(!c(Dimensoes,Sucesso))%>% pivot_longer(everything(), names_to = "Nome" , values_to = "Descricao")
    notas <- results_raw%>%
      unnest(Dimensoes)%>%
      select(Descricao_Dim)%>%
      unnest(Descricao_Dim)%>%
      select(!dim_num)%>%
      rename("Nome" = abrv , "Descricao" = versao)
    
    final_result <- bind_rows(names,notas)
    
    meta_list[[indicators_current]]<- final_result
  }
  return(meta_list)
}
  
a <- fromJSON(
      paste0(
        "https://www.ine.pt/ine/json_indicador/pindicaMeta.jsp?varcd=0005611",
        "&lang=PT"
      ))

%>%
  select(!c(Dimensoes,Sucesso))
         
colnames(a)

numbers <- Indicadores$`Código de difusão`
l <- length(numbers)

for(i in 1:5 ){
    result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0008614","&Dim1=T&lang=PT"))
  if (!("IndicadorCod" %in% colnames(result))) {
    numbers <- numbers[-i]
    l <- l - 1
    i <- i - 1
  } else {
    assign(result$IndicadorDsg,as.data.frame(result$Dados))
    d1 <- unnest_longer(result$Dados,col = colnames(result$IndicadorDsg),names_repair = "minimal")
    write_csv(d2,file = paste0("datasets/",numbers[i],".csv"))
  }
   if (i %% 100 == 0) {
      Sys.sleep(60)
  }
}


# pop_2013 <- read_csv("outputs/pop_2013.csv")%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2014 <- read_csv("outputs/pop_2014.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2015 <- read_csv("outputs/pop_2015.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2016 <- read_csv("outputs/pop_2016.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2017 <- read_csv("outputs/pop_2017.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2018 <- read_csv("outputs/pop_2018.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2019 <- read_csv("outputs/pop_2019.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2020 <- read_csv("outputs/pop_2020.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# pop_2021 <- read_csv("outputs/pop_2021.csv", 
#     col_types = cols(dim_4 = col_number(), 
#         valor = col_number()))%>%
#     filter(dim_3_t!="HM")%>%
#     mutate(municip = case_when(
#       geocod=="1113101" ~ "Calheta [R.A. Madeira]",
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]",
#       geocod=="1114501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="1114201" ~ "Lagoa [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#     left_join(linkage_geo, join_by(municip==municip))
# 
# 
# fwrite(pop_2013,file = paste0("datasets/pop_2013.csv"), bom = T)
# 
# fwrite(pop_2014,file = paste0("datasets/pop_2014.csv"), bom = T)
# 
# fwrite(pop_2015,file = paste0("datasets/pop_2015.csv"), bom = T)
# 
# fwrite(pop_2016,file = paste0("datasets/pop_2016.csv"), bom = T)
# 
# fwrite(pop_2017,file = paste0("datasets/pop_2017.csv"), bom = T)
# 
# fwrite(pop_2018,file = paste0("datasets/pop_2018.csv"), bom = T)
# 
# fwrite(pop_2019,file = paste0("datasets/pop_2019.csv"), bom = T)
# 
# fwrite(pop_2020,file = paste0("datasets/pop_2020.csv"), bom = T)
# 
# fwrite(pop_2021,file = paste0("datasets/pop_2021.csv"), bom = T)


```

# Test V1

## Pop censitária - 2021

População por municipio à data do CENSUS 2021

```{r, eval=FALSE}
#| code-fold: true
#| code-summary: "Mostrar Código"
library(rio)
codigos_df <- import("datasets/geo_linkage_2024_v2.csv", colClasses=c("character"))
# 
# 
numbers <- as.character(codigos_df$dicofre_2013)

numbers_done <- unique(d3$geocod)
teste <- setdiff(numbers, numbers_done)
numbers <- teste

df3 <- data.frame()

if(!"valor" %in% colnames(df3 )){
        df3 <- data.frame(geocod=0, geodsg=0, valor=0,obs=0, year=0)
      }


l <- length(numbers)
for(i in 1:l ){
    result<- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0011626&Dim1=T&Dim2=",numbers[i],"&lang=PT"))
    pop <- as.data.frame(result$Dados$'2021')
   if (i %% 99 == 0) {
      Sys.sleep(2)
   }
  if(i==1){
  d2 <- pop
  }else{
    d2 <- rbind(d2,pop)
  }
  print(l)
}

d2_2 <- d2 |>
  distinct()

d3 <- rbind(d2_1,d2_2)

d2 <- d2 %>%
  mutate(municip = case_when(
      geocod=="1113101" ~ "Calheta [R.A. Madeira]",
      geocod=="1114501" ~ "Calheta [R.A. Açores]",
      geocod=="1114201" ~ "Lagoa [R.A. Açores]",
      TRUE ~ as.character(geodsg)))

fwrite(d3,file = paste0("datasets/pop_2021_freg.csv"), bom = T)

```

# Improvements

## Linkage geo

Vlookup in R - Merge function

```{r}
linkage_geo <- read_csv("datasets/linkage_geo.csv")%>%  
  mutate(last_4 = as.character(substr(cod_geo, nchar(cod_geo)-3,nchar(cod_geo))))

linkage_geo_freg <- read_csv2("datasets/categorias_geo_freg.csv")%>%
  select(-municip)%>%
  rename(last_4 =pair)%>%
  left_join(linkage_geo,by = "last_4")

linkage_geo <- linkage_geo %>%
  select(geo, ars, nuts3, aces2, nuts1, nuts2, cod_geo_nuts2002, cod_geo)%>%
  rename(municip="geo")%>%
  mutate(municip= recode(municip, "Calheta"="Calheta [R.A. Madeira]"))%>%
  rename(geocod = "cod_geo")
```

Pivot Individual

```{r, eval=FALSE}
#| code-fold: true
#| code-summary: "Mostrar Código"
d3 <- d2%>%
  select(-dim_3,-dim_4)%>%
  pivot_wider(names_from = dim_4_t,values_from = valor)%>%

write_csv(d3,file = paste0("datasets/pop_base_2021_anos.csv"))
```

Pivot quinquenal

```{r, eval=FALSE}
#| code-fold: true
#| code-summary: "Mostrar Código"

d2$dim_4 <- as.numeric(d2$dim_4)
d2$valor <- as.numeric(d2$valor)
#grupos etários
gr_1  <- c(1)        #<1 ano
gr_2  <- c(2:5)    #0 - 4 anos
gr_3  <- c(6:10)   #5 - 9 anos
gr_4  <- c(11:15)  #10 - 14 anos
gr_5  <- c(16:20)  #15 - 19 anos
gr_6  <- c(21:25)  #20 - 24 anos
gr_7  <- c(26:30)  #25 - 29 anos
gr_8  <- c(31:35)  #30 - 34 anos
gr_9  <- c(36:40)  #35 - 39 anos
gr_10 <- c(41:45)  #40 - 44 anos
gr_11 <- c(46:50) #45 - 49 anos
gr_12 <- c(51:55)  #50 - 55 anos
gr_13 <- c(56:60)  #56 - 59 anos
gr_14 <- c(61:65)  #60 - 65 anos
gr_15 <- c(66:70)  #65 - 69 anos
gr_16 <- c(71:75)  #70 - 74 anos
gr_17 <- c(76:80)  #75 - 80 anos
gr_18 <- c(81:85)  #81 - 85 anos
gr_19 <- c(86:101)  #85 e mais anos
gr_20 <- c("T")  #Totais

munucip_pop_age <- d2 %>%
  mutate(etario = case_when(
    dim_4 %in% gr_1 ~ "<1 ano"
    ,dim_4 %in% gr_2 ~ "0 - 4 anos"
    ,dim_4 %in% gr_3 ~ "5 - 9 anos"
    ,dim_4 %in% gr_4 ~ "10 - 14 anos"
    ,dim_4 %in% gr_5 ~ "15 - 19 anos"
    ,dim_4 %in% gr_6 ~ "20 - 24 anos"
    ,dim_4 %in% gr_7 ~ "25 - 29 anos"
    ,dim_4 %in% gr_8 ~ "30 - 34 anos"
    ,dim_4 %in% gr_9 ~ "35 - 39 anos"
    ,dim_4 %in% gr_10 ~ "40 - 44 anos"
    ,dim_4 %in% gr_11 ~ "45 - 49 anos"
    ,dim_4 %in% gr_12 ~ "50 - 54 anos"
    ,dim_4 %in% gr_13 ~ "55 - 59 anos"
    ,dim_4 %in% gr_14 ~ "60 - 64 anos"
    ,dim_4 %in% gr_15 ~ "65 - 69 anos"
    ,dim_4 %in% gr_16 ~ "70 - 74 anos"
    ,dim_4 %in% gr_17 ~ "75 - 80 anos"
     ,dim_4 %in% gr_18 ~ "81 - 84 anos"
     ,dim_4 %in% gr_19 ~ "85 e mais anos"
     ,dim_4 %in% gr_20 ~ "Total"
   )) %>%
   select(-dim_4,-dim_3,-dim_4_t)%>%
   group_by(etario)%>%
   pivot_wider(names_from = etario,values_from = valor, values_fn =sum)%>%
   rename(Total = "NA")%>%
   replace(is.na(.),0)%>%
   left_join(linkage_geo, by = "municip")

 #Reordenar colunas
 munucip_pop_age2 <- munucip_pop_age[,c(1,2,3,4,24,25,26,27,6,11,15,9,7,8,21,16,10,13,18,14,17,19,12,23,22,5,20)]
#
 munucip_pop_age2 <- munucip_pop_age2%>%
   filter(dim_3_t == "H" | dim_3_t == "M" )
#
 munucip_pop_age <- d2 %>%
   mutate(etario = case_when(
     dim_4 %in% gr_1 ~ "<1 ano"
    ,dim_4 %in% gr_2 ~ "0 - 4 anos"
    ,dim_4 %in% gr_3 ~ "5 - 9 anos"
    ,dim_4 %in% gr_4 ~ "10 - 14 anos"
    ,dim_4 %in% gr_5 ~ "15 - 19 anos"
    ,dim_4 %in% gr_6 ~ "20 - 24 anos"
    ,dim_4 %in% gr_7 ~ "25 - 29 anos"
     ,dim_4 %in% gr_8 ~ "30 - 34 anos"
     ,dim_4 %in% gr_9 ~ "35 - 39 anos"
     ,dim_4 %in% gr_10 ~ "40 - 44 anos"
     ,dim_4 %in% gr_11 ~ "45 - 49 anos"
     ,dim_4 %in% gr_12 ~ "50 - 54 anos"
     ,dim_4 %in% gr_13 ~ "55 - 59 anos"
     ,dim_4 %in% gr_14 ~ "60 - 64 anos"
     ,dim_4 %in% gr_15 ~ "65 - 69 anos"
     ,dim_4 %in% gr_16 ~ "70 - 74 anos"
     ,dim_4 %in% gr_17 ~ "75 - 80 anos"
     ,dim_4 %in% gr_18 ~ "81 - 84 anos"
     ,dim_4 %in% gr_19 ~ "85 e mais anos"
     ,dim_4 %in% gr_20 ~ "Total"
  )) %>%
    select(-dim_4,-dim_3,-dim_4_t)%>%
   filter(dim_3_t %in% c("H", "M") & is.na(etario)==FALSE)%>%
   rename(populacao = valor, sexo = dim_3_t )%>%
   group_by(geocod,municip,sexo,etario )%>%
   summarise(populacao= sum(populacao))%>%
  left_join(linkage_geo, by = "municip")



 fwrite(munucip_pop_age,file = paste0("outputs/munucip_pop_age_long.csv"), bom = T)
fwrite(munucip_pop_age2,file = paste0("outputs/munucip_pop_age_wide.csv"), bom = T)
```

## Teste V1.1 - Indicador 0008273

População residente (N.º) por Local de residência (NUTS - 2013), Sexo e Grupo etário; Anual - 2011- 2020

```{r ,eval=FALSE}
#| code-fold: true
#| code-summary: "Mostrar Código"

codigos_df <- read_excel("datasets/ref_geo.xlsx")
# &Dim2=", numbers[i], "
numbers <-linkage_geo$cod_geo

anos_cod <- c("pop_2011","pop_2012","pop_2013","pop_2014","pop_2015","pop_2016","pop_2017","pop_2018","pop_2019","pop_2020")

years <- c("2011","2012","2013","2014","2015","2016","2017","2018","2019","2020")

l <- length(numbers)

y <- length(years)

t <- length(anos_cod)

result_list <- list()

for (i in 1:l) {
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0008273&Dim1=T&Dim2=", numbers[i],"&lang=PT"))
  for (i in 1:y) {
    pop <- as.data.frame(result$Dados)
    pop <- pop %>%
          unnest(years[i])%>%
          select(geocod,geodsg,dim_3,dim_3_t,dim_4,dim_4_t,valor)
    result_list[[anos_cod[i]]] <- rbind(result_list[[anos_cod[i]]], pop)
  }
  if (i %% 100 == 0) {
    Sys.sleep(60)
  }
  Sys.Sleep(2)
}
for (i in 1:y) {
  assign(anos_cod[i], result_list[[anos_cod[i]]])%>% mutate(municip = case_when(
      geocod=="3003101" ~ "Calheta [R.A. Madeira]",
      geocod=="2004501" ~ "Calheta [R.A. Açores]",
      geocod=="2004201" ~ "Lagoa [R.A. Açores]",
      TRUE ~ as.character(geodsg)))%>%fwrite(file = paste0("outputs/",anos_cod[i],".csv"), bom = T)
}

```

```{r ,include=FALSE, eval=FALSE}
# Teste 1.2 - 

# População residente (N.º) por Local de residência (NUTS - 2013), Sexo e Grupo etário; Anual - 2011- 2020
numbers <-linkage_geo$cod_geo_nuts2002
numbers

anos_cod <- c("pop_2001","pop_2002","pop_2003","pop_2004","pop_2005","pop_2006","pop_2007","pop_2008","pop_2009","pop_2010")

years <- c("2001","2002","2003","2004","2005","2006","2007","2008","2009","2010")

l <- length(numbers)

y <- length(years)

result_list <- list()

for (i in 1:l) {
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0003182&Dim1=T&Dim2=", numbers[i], "&lang=PT"))
  for (i in 1:y) {
    pop <- as.data.frame(result$Dados)
    pop <- pop %>%
          unnest(years[i])%>%
          select(geocod,geodsg,dim_3,dim_3_t,dim_4,dim_4_t,valor)
    result_list[[anos_cod[i]]] <- rbind(result_list[[anos_cod[i]]], pop)
  }
  if (i %% 100 == 0) {
    Sys.sleep(60)
  }
}
for (i in 1:y) {
  assign(anos_cod[i], result_list[[anos_cod[i]]])%>% mutate(municip = case_when(
      geocod=="3003101" ~ "Calheta [R.A. Madeira]",
      geocod=="2004501" ~ "Calheta [R.A. Açores]",
      geocod=="2004201" ~ "Lagoa [R.A. Açores]",
      TRUE ~ as.character(geodsg)))%>%fwrite(file = paste0("outputs/",anos_cod[i],".csv"), bom = T)
}
```

# Extrator Universal de Indicadores do INE para Diagnóstico - Municipio, NUTSIII, NUTSII e NUTSI - V2.0 - Faster, Stronger, Better

O que é suposto:

Definir indicadores a extrair - variável indicador - colocar entre aspas

Pode ser possível extrair os últimos x observacoes - Definido pela variável X

```{r, include=FALSE}
linkage_geo <- read_csv("datasets/linkage_geo.csv")

linkage_geo <- linkage_geo %>%
  select(geo, ars, nuts3, aces2, nuts1, nuts2, cod_geo_nuts2002, cod_geo)  %>%
  rename(municip="geo")%>%
  mutate(municip= recode(municip, "Calheta"="Calheta [R.A. Madeira]"))

#TOTAL DE INDICADORES

Indicadores <- read_excel("datasets/Indicadores.xlsx", skip = 14)

Indicadores <- Indicadores %>%
  filter(`Disponível no Portal`== "Sim")

#indicador <- Indicadores$`Código de difusão`

#DEFINIR INDICADORES A RETIRAR

indicador <- c("0008614","0009817") 

#TERMO DE DESAGREGACAO POR LOCALIZACAO GEOGRAFICA
desag <- "&Dim2="

#CODIGOS GEOGRAFICOS NUTSIII PARA 2012 e 2002
cod_2002 <-linkage_geo$cod_geo_nuts2002
cod_2002 <- cod_2002[! cod_2002 %in% c("9999999", "0")]
cod_2014 <- linkage_geo$geocod
cod_2014 <- cod_2014[! cod_2014 %in% c("9999999", "0")]

#CODIGOS PARA NUTSII
nuts_ii_cod <- c("PT","11","16","17","18","19","20","30")

#DEFINIR ANOS A RETIAR Minimo 2
obs_back <- 10

# DEFINICOES BASEADO NO COLOCADO EM CIMA

a <- length(indicador)

b <- length(cod_2014) 

c <- length(nuts_ii_cod)

#A API DO INE TEM UM LIMITE DE REQUESTS LOGO E CRIADO UM VALOR QUE VAI AUMENTANDO COM AS REQUESTS QUE SAO FEITAS
 
counter <- 1

#LIMPA A ESTRACAO ANTERIOR
result_list <- list()

#FUNCAO DE SLEEP - funciona se sleep e 60, 30, 20, 10, 

sleep <- function(z){
  if (z %% 100 == 0) {
    Sys.sleep(5)
    z <- 1
  }else{
      z <- z+1
  }
} 
```

```{r, include=FALSE}
# save_to_result_list <- function(y){
#   #Segundo loop baseado na desagregação maxima conseguida
#     colunas_nanos <- colnames(dados)
#     num_colunas <- length(colunas_nanos)
#     obs_back  <- as.numeric(colunas_nanos[num_colunas])
#     if(year_back > num_colunas){
#         x <- num_colunas
#     }else{
#       x <-  year_back
#     }
#     obs_back s <- as.character(c((obs_back -x):(obs_back )))
#     each_df <- y %>%
#       select(obs_back s[1])%>%
#       unnest(obs_back s[1])
#     colunas_por_ano <- colnames(each_df)
#     for (i in 1:x) {
#     #ver e retirar os nomes das colunas de cada ano para o select
#     dados1 <- dados %>%
#         unnest(obs_back s[i])%>%
#         select(all_of(colunas_por_ano))
#     result_list[[obs_back s[i]]] <- rbind(result_list[[obs_back s[i]]], dados1)
#     }
#     return(obs_back )
#     return(x)
#     return(result_list)
# }
# 
# write_output <- function(v){
#   x <- length(as.data.frame(v))
#   for (i in 1:x) {
#     nomedf <- paste0(indicador_atual,"_",obs_back s[i],"_",agreg)
#     full_df <- v[[obs_back s[i]]]%>% 
#       mutate(municip = case_when(
#       geocod=="3003101" ~ "Calheta [R.A. Madeira]", 
#       geocod=="2004501" ~ "Calheta [R.A. Açores]",
#       geocod=="2004201" ~ "Lagoa [R.A. Açores]",
#       TRUE ~ as.character(geodsg)))%>%
#       fwrite(file = paste0("outputs/",nomedf,".csv"), bom = T)
#   }
#   result_list <- list()
# }
# 
```

-   Pensar em Refazer com o flatten command

    -   Ainda por resolver\_

```{r, eval=FALSE}
#Falta codigo de debugging

for (k in 1:a) {
  #COMECA POR LER O INDICADOR A RETIRAR
  indicador_atual <- indicador[k]
  counter <- sleep(counter)
  #TESTA A DESAGREGAGACAO DE 2014
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, cod_2014[79], "&lang=PT"))
  result <- as.data.frame(result)
  #OS DADOS DO INE VEM COM MI E DADOS - PARA A EXTRACAO
  if (("IndicadorCod" %in% colnames(result))){ 
  for (w in 1:b) {
  #retirar indicador com desagregação municipio 2014
  counter <- sleep(counter)
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, cod_2014[w], "&lang=PT"))
  agreg <- "NUTSIII"
  dados <- as.data.frame(result$Dados)
  colunas_nanos <- colnames(dados)
    num_colunas <- length(colunas_nanos)
    if(obs_back > num_colunas){
        x <- num_colunas
    }else{
      x <-  obs_back
    }
    obs_nome <- as.character(c(colunas_nanos[(num_colunas-x):(num_colunas)]))
    for (i in 1:x) {
    #ver e retirar os nomes das colunas de cada ano para o select
    obs_nome2 <-  obs_nome[-i]
    dados1 <- dados %>%
        unnest(obs_nome[i])%>%
        select(-all_of(obs_nome2))
    result_list[[obs_nome[i]]] <- bind_rows(result_list[[obs_nome[i]]], dados1)
  Sys.sleep(1)
    }}
    if (w %% 100 == 0) {
      print(cod_2014[w])
   }
    }
  else if(length(result_list)==0){
  counter <- sleep(counter)
  #TESTA A DESAGREGAGACAO DE 2002
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",desag, cod_2002[1], "&lang=PT"))
  result <- as.data.frame(result)
  if (("IndicadorCod" %in% colnames(result))) {
  #retirar indicador com desagregação municipio 2002
  for (e in 1:b) {
  counter <- sleep(counter)
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",desag, cod_2002[e], "&lang=PT"))
  agreg <- "NUTSIII"
  dados <- as.data.frame(result$Dados)
  colunas_nanos <- colnames(dados)
    num_colunas <- length(colunas_nanos)
    if(obs_back > num_colunas){
        x <- num_colunas
    }else{
      x <-  obs_back
    }
    obs_nome <- as.character(c(colunas_nanos[(num_colunas-x):(num_colunas)]))
    for (i in 1:x) {
    #ver e retirar os nomes das colunas de cada ano para o select
    obs_nome2 <-  obs_nome[-i]
    dados1 <- dados %>%
        unnest(obs_nome[i])%>%
        select(-all_of(obs_nome2))
    result_list[[obs_nome[i]]] <- bind_rows(result_list[[obs_nome[i]]], dados1)
  Sys.sleep(1)
    }}
    if (e %% 100 == 0) {
      print(cod_2014[e])
   }
  }
  }
  else if(length(result_list)==0){
  counter <- sleep(counter)
  #TESTA A DESAGREGAGACAO DE NUTSII
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",desag, nuts_ii_cod[1], "&lang=PT"))
  result <- as.data.frame(result)
  if (("IndicadorCod" %in% colnames(result))) {
  #retirar indicador com desagregação NUTSII
  for (r in 1:c) {
  counter <- sleep(counter)
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual ,"&Dim1=T",desag, nuts_ii_cod[r], "&lang=PT"))
  agreg <- "NUTSII"
  dados <- as.data.frame(result$Dados)
  colunas_nanos <- colnames(dados)
    num_colunas <- length(colunas_nanos)
    if(obs_back > num_colunas){
        x <- num_colunas
    }else{
      x <-  obs_back
    }
    obs_nome <- as.character(c(colunas_nanos[(num_colunas-x):(num_colunas)]))
    for (i in 1:x) {
    #ver e retirar os nomes das colunas de cada ano para o select
    obs_nome2 <-  obs_nome[-i]
    dados1 <- dados %>%
        unnest(obs_nome[i])%>%
        select(-any_of(obs_nome2))
    result_list[[obs_nome[i]]] <- bind_rows(result_list[[obs_nome[i]]], dados1)
  Sys.sleep(1)
    }}
  }
  }
  else{
  counter <- sleep(counter)
  #TESTA A DESAGREGAGACAO NACIONAL OU FORA DO PADRAO
  result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T&lang=PT"))
  if (("IndicadorCod" %in% colnames(result))) {
  #retirar indicador sem desagragação
  agreg <- "nacional"
  result <- as.data.frame(result)
   dados <- as.data.frame(result$Dados)
  colunas_nanos <- colnames(dados)
    num_colunas <- length(colunas_nanos)
    if(obs_back > num_colunas){
        x <- num_colunas
    }else{
      x <-  obs_back
    }
    obs_nome <- as.character(c(colunas_nanos[(num_colunas-x):(num_colunas)]))
    for (i in 1:x) {
    #ver e retirar os nomes das colunas de cada ano para o select
    obs_nome2 <-  obs_nome[-i]
    dados1 <- dados %>%
        unnest(obs_nome[i])%>%
        select(-all_of(obs_nome2))
    result_list[[obs_nome[i]]] <- bind_rows(result_list[[obs_nome[i]]], dados1)
  Sys.sleep(1)
    }}
  }
  if (length(result_list)!=0){
     x <- length(result_list)
    for (i in 1:x) {
      nomedf <- paste0(indicador_atual,"_",obs_nome[i],"_",agreg)
      assign(paste0("full_df"), as.data.frame(result_list[[obs_nome[i]]])%>% 
      select(-any_of(colunas_nanos))%>%left_join(linkage_geo, by="geocod"))
      fwrite(full_df, file = paste0("outputs/",nomedf,".csv"), bom = T)
  }
  }
  if (k == k) {
    print(indicador_atual)
    result_list <- list()
   }
}
```

## Testing a rejoin code

```{r, echo=FALSE}
# Get a list of file names
file_names <- list.files(path = "outputs", pattern = ".*\\.csv")

# Initialize a list to store the data frames
df_list <- list()
#FOR LOOP
for (file_name in file_names) {
  # Split the file name into its components
  components <- strsplit(file_name, c("_"))[[1]]
  
    # Remove the ".csv" extension from the last component
  last_component <- sub(".csv", "", components[length(components)])
  components[length(components)]
  # Replace the last component in the components vector
  components[length(components)] <- last_component
  # Assign the components to variables
  indicador <- components[1]
  year <- components[2]
  aggregation <- components[3]
  
  # Load the file into a data frame
  df <- read.csv(file.path("outputs", file_name))
  
  # Add columns for year and aggregation
  df <- cbind(df, year = year, aggregation = aggregation)
  
  # Check if a data frame for this indicator already exists
  if (!(indicador %in% names(df_list))) {
    # If not, create a new data frame for this indicator
    df_list[[indicador]] <- df
  } else {
    # If it does, use rbind to combine the data frames
    df_list[[indicador]] <- rbind(df_list[[indicador]], df)
  }
}

# Write each data frame to a separate CSV file
for (df_name in names(df_list)) {
  df <- df_list[[df_name]]
  write.csv(df, file.path("outputs", paste0(df_name, ".csv")))
}



#MAP FUNCTION DOES NOT WORK

# # Use map to process each file name
# map(file_names, function(file_name, df_list) {
#   # Split the file name into its components
#   components <- strsplit(file_name, "_")[[1]]
#   
#   # Assign the components to variables
#   indicador <- components[1]
#   year <- components[2]
#   aggregation <- components[3]
#   
#   # Load the file into a data frame
#   df <- read.csv(file.path("outputs", file_name))
#   
#   # Add columns for year and aggregation
#   df <- cbind(df, year = year, aggregation = aggregation)
#   # Check if a data frame for this indicator already exists
#   if (!(indicador %in% names(df_list))) {
#     # If not, create a new data frame for this indicator
#     df_list[[indicador]] <- df
#   } else {
#     # If it does, use rbind to combine the data frames
#     df_list[[indicator]] <- rbind(df_list[[indicator]], df)
#   }
# }, df_list)
```

## Extrator Universal para indicadores com Freguesia - Confirmar - Ainda por fazer - ponderar fazer?

```{r include=FALSE}
# Get a list of file names


# linkage_geo_freg <- read_csv2("datasets/categorias_geo_freg.csv")%>%
#   select(-municip)%>%
#   rename(last_4 =pair)%>%
#   left_join(linkage_geo,by = "last_4" )
# 
# 
# cod_6 <- linkage_geo_freg$Código
# 
# indicador <- c("0003182")
# 
# for (i in 1:a) {
#   indicador_atual <- indicador[i]
#   counter <- sleep(counter)
#   result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, cod_6[79], "&lang=PT"))
#   result <- as.data.frame(result)
#   if (("IndicadorCod" %in% colnames(result))){ 
#   for (w in 1:b) {
#   #retirar indicador com desagregação municipio 2014
#   counter <- sleep(counter)
#   result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, cod_6[w], "&lang=PT"))
#   agreg <- "freguesia"
#   result <- as.data.frame(result)
#   colunas_nanos <- colnames(dados)
#     num_colunas <- length(colunas_nanos)
#     obs_back  <- as.numeric(colunas_nanos[num_colunas])
#     if(year_back > num_colunas){
#         x <- num_colunas
#     }else{
#       x <-  year_back
#     }
#     obs_back s <- as.character(c((obs_back -x):(obs_back )))
#     each_df <- y %>%
#       select(obs_back s[1])%>%
#       unnest(obs_back s[1])
#     colunas_por_ano <- colnames(each_df)
#     for (i in 1:x) {
#     #ver e retirar os nomes das colunas de cada ano para o select
#     dados1 <- dados %>%
#         unnest(obs_back s[i])%>%
#         select(all_of(colunas_por_ano))
#     result_list[[obs_back s[i]]] <- rbind(result_list[[obs_back s[i]]], dados1)
#   Sys.sleep(2)
#     }}
#     if (w %% 100 == 0) {
#       print(cod_6[w])
#    }
#     }
#   else{
#   counter <- sleep(counter)
#   result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T&lang=PT"))
#   if (("IndicadorCod" %in% colnames(result))) {
#   #retirar indicador sem desagragação
#   agreg <- "nacional"
#   result <- as.data.frame(result)
#     dados <- as.data.frame(result$Dados)
#   colunas_nanos <- colnames(dados)
#     num_colunas <- length(colunas_nanos)
#     obs_back  <- as.numeric(colunas_nanos[num_colunas])
#     if(year_back > num_colunas){
#         x <- num_colunas
#     }else{
#       x <-  year_back
#     }
#     obs_back s <- as.character(c((obs_back -x):(obs_back )))
#     each_df <- dados %>%
#       select(obs_back s[1])%>%
#       unnest(obs_back s[1])
#     colunas_por_ano <- colnames(each_df)
#     for (i in 1:x) {
#     #ver e retirar os nomes das colunas de cada ano para o select
#     dados1 <- dados %>%
#         unnest(obs_back s[i])%>%
#         select(all_of(colunas_por_ano))
#     result_list[[obs_back s[i]]] <- rbind(result_list[[obs_back s[i]]], dados1)
#   Sys.sleep(2)
#   }
#   }
#   }
#   if (length(result_list)!=0){
#      x <- length(result_list)
#     for (i in 1:x) {
#       nomedf <- paste0(indicador_atual,"_",obs_back s[i],"_",agreg)
#       full_df <- result_list[[obs_back s[i]]]%>% 
#       fwrite(file = paste0("outputs/",nomedf,".csv"), bom = T)
#   }
#   }
#   if (i == i) {
#       print(indicador_atual)
#    }
# }

        # obs_nome <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
        # i <- 1
        # for (i in 1:x) {
        #   #ver e retirar os nomes das colunas de cada ano para o select
        #   obs_nome2<-obs_nome[-i]
        #   dados1<- dados %>%
        #     unnest(obs_nome[i])%>%
        #     select(-all_of(obs_nome2))
        # 
        #   result_list[[obs_nome[i]]] <- bind_rows(result_list[[obs_nome[i]]], dados1)
        #   Sys.sleep(1)
```

as.character(geo_ref_by)

```{r}
#indicadores é o vetor com os indicadores
#largest_area- filtered dataframe with all codes needed to run
#obs_back- número de observações
  indicadores <- c("0008711")
  obs_back <- 10
  result_list <- list()
  largest_area <- geolinkage_aces
#FUNCAO DE SLEEP - funciona se sleep e 60, 30, 20, 10, 

sleep <- function(z){
  if (z %% 100 == 0) {
    Sys.sleep(5)
    z <- 1
  }else{
      z <- z+1
  }
} 


ine.get <- function(indicadores,largest_area,obs_back,result_list) {

  a <- length(indicadores)
  dicofre_2013 <- unique(largest_area$dicofre_2013)
  municipio_2013 <- unique(largest_area$municipio_2013_cod)
  municipio_2002 <- unique(largest_area$municipio_2002_cod)
  nuts_3_2013 <- unique(largest_area$nuts3_2013_cod)
  nuts_3_2002 <- unique(largest_area$nuts3_2002_cod)
  nuts_2_2002 <- unique(largest_area$nuts2_2013_cod)
  nuts_1 <- unique(largest_area$nuts2_2013_cod)
  
  counter <- 0
  #Existem 2 desagregacoes que estao hard-coded porque sao iguais entre 2013 e 2002
  test <- c("&Dim2=11102&lang=PT",  #Testa a desagregação por freguesias
              "&Dim2=16E0111&lang=PT",#Testa a desagregação por municipio 2013
              "&Dim2=1610111&lang=PT",#Testa a desagregação por municipio 2002
              "&Dim2=16E&lang=PT",    #Testa a desagregação por NUTSIII 2013
              "&Dim2=161&lang=PT",    #Testa a desagregação por NUTSIII 2002
              "&Dim2=16&lang=PT",     #Testa a desagregação por NUTSII 2013
              ""                      #Testa a desagregação por NUTSI ou sem padrão 
              )
  codes_list <- list(dicofre_2013,municipio_2013,municipio_2002,nuts_3_2013,nuts_3_2002,nuts_2_2002,"")
  b_list <- list(length(dicofre_2013),length(municipio_2013),length(municipio_2002),length(nuts_3_2013),length(nuts_3_2002),length(nuts_2_2002),1)
  agreg_list <- list("Freguesia","Municipio","Municipio","NUTSIII","NUTSIII","NUTSII","Nacional")
  desag_v <- c("&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","")
  # geo_ref_df <- list(dicofre_2013,municipio_2013_cod,municipio_2002_cod,nuts3_2013_codnuts3_2002_cod,nuts2_2013_cod,nuts_1)
  geo_ref_by_v <- c("dicofre_2013",
                  "municipio_2013_cod",
                  "municipio_2002_cod",
                  "nuts3_2013_cod",
                  "nuts3_2002_cod",
                  "nuts2_2013_cod",
                  "nuts_1_2013_cod")
  for (k in 1:a) {
    #COMECA POR LER O INDICADOR A RETIRAR
    indicador_atual <- indicadores[k]
    counter <- sleep(counter)
    result <- list()
    for (k in 1:length(test)){
      counter <- sleep(counter)
      test[[k]] <- as.data.frame(fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",test[k],"&lang=PT")))
    }
    r <- 1
    b <- b_list[[1]]
    codes <- codes_list[[1]]
    agreg <- agreg_list[[1]]
    desag <- desag_v[1]
    # geo_ref_df <- geo_ref[[1]]
    geo_ref_by <- geo_ref_by_v[1]
    while("Falso" %in% colnames(test[[r]]$Sucesso)){
      r <- r + 1
      b <- b_list[[r]]
      codes <- codes_list[[r]]
      agreg <- agreg_list[[r]]
      desag <- desag_v[r]
      # geo_ref_df <- geo_ref[[r]]
      geo_ref_by <- geo_ref_by_v[r]
    }
    for (w in 1:b){
        counter <- sleep(counter)
        result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, codes[w],"&lang=PT"))
        dados <- as.data.frame(result$Dados)
        colunas_nanos <- colnames(dados)
        num_colunas <- length(colunas_nanos)
        if(obs_back > num_colunas){
          x <-num_colunas
        }else{
          x <-obs_back
        }
        # Get column names for years of interest
        obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
        df_all <- data.frame()
        # Loop over years
        for (obs in obs_cols) {
          # Remove all columns except current year
          df <- dados %>%
            unnest(!!sym(obs))%>%
            select(-any_of(colunas_nanos))%>%
            mutate(obs=as.character(obs))%>%
            left_join(largest_area, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
          # Add data frame to list
          df_all <- bind_rows(df_all, df)
          # Pause for 1 second
          Sys.sleep(1)
        }
        if(w==1){
          result_list[[indicador_atual]] <- df_all
        }
        else{
    result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
        }
      }
  return(result_list)
  }
}  
        #still working on the END
    # if (length(result_list)!=0){
    #   x <- length(result_list)
    #   for (i in 1:x) {
    #     nomedf <- paste0(indicador_atual,"_",obs_nome[i],"_",agreg)
    #     assign(paste0("full_df"), as.data.frame(result_list[[obs_nome[i]]])%>%
    #              select(-any_of(colunas_nanos)))
                 # left_join(linkage_geo, by="geocod"))
        # fwrite(full_df, file = paste0("outputs/",nomedf,".csv"), bom = T)
    # }
```

left_join(largest_area, by("geocod" = as.character(geo_ref_by)))

```{r}
setwd("C:/Users/jdrdionisio/Desktop/RProjects/Projects/INE/INE_API/")

geolinkage_path <- "datasets/geolinkage_aces_2022.csv"
geolinkage_aces <- read_csv(geolinkage_path,col_types = cols(.default = "c"))
colnames(geolinkage_aces) 
# result_list <- list()
largest_area <- geolinkage_aces 
obs_back <- 10
indicadores <- c("0008711",	0008079)
result_list <- list()
# result_list <- list()
# largest_area <- geolinkage_aces %>%
#   filter(aces_2022=="ACES Baixo Mondego")

sleep <- function(z){
  if (z %% 100 == 0) {
    Sys.sleep(5)
    z <- 1
  }else{
    z <- z+1
  }
  return(z)
  }

# ine.get <- function(indicadores,largest_area,obs_back,result_list) {
  a <- length(indicadores)
  dicofre_2013 <- unique(largest_area$dicofre_2013)
  municipio_2013 <- unique(largest_area$municipio_2013_cod)
  municipio_2002 <- unique(largest_area$municipio_2002_cod)
  nuts_3_2013 <- unique(largest_area$nuts3_2013_cod)
  nuts_3_2002 <- unique(largest_area$nuts3_2002_cod)
  nuts_2_2013 <- unique(largest_area$nuts2_2013_cod)
  nuts_1 <- unique(largest_area$nuts1_2013_cod)
  counter <- 0
  #Existem 2 desagregacoes que estao hard-coded porque sao iguais entre 2013 e 2002
  testd <- c("&Dim2=11102&lang=PT",  #Testa a desagregação por freguesias
            "&Dim2=16E0111&lang=PT", #Testa a desagregação por municipio 2013
            "&Dim2=1610111&lang=PT", #Testa a desagregação por municipio 2002
            "&Dim2=16E&lang=PT",     #Testa a desagregação por NUTSIII 2013
            "&Dim2=161&lang=PT",     #Testa a desagregação por NUTSIII 2002
            "&Dim2=16&lang=PT",      #Testa a desagregação por NUTSII 2013
            "&lang=PT"               #Testa a desagregação por NUTSI ou sem padrão 
  )
  codes_list <- list(dicofre_2013,municipio_2013,municipio_2002,nuts_3_2013,nuts_3_2002,nuts_2_2013,"")
  b_list <- list(length(dicofre_2013),length(municipio_2013),length(municipio_2002),length(nuts_3_2013),length(nuts_3_2002),length(nuts_2_2013),1)
  agreg_list <- list("Freguesia","Municipio","Municipio","NUTSIII","NUTSIII","NUTSII","Nacional")
  desag_v <- c("&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","")
  # geo_ref_df <- list(dicofre_2013,municipio_2013_cod,municipio_2002_cod,nuts3_2013_codnuts3_2002_cod,nuts2_2013_cod,nuts_1)
  geo_ref_by_v <- c("dicofre_2013",
                    "municipio_2013_cod",
                    "municipio_2002_cod",
                    "nuts3_2013_cod",
                    "nuts3_2002_cod",
                    "nuts2_2013_cod",
                    "nuts1_2013_cod")
  for (i in 1:a) {
    #COMECA POR LER O INDICADOR A RETIRAR
    indicador_atual <- indicadores[i]
    counter <- sleep(counter)
    test <- list()
    for (k in 1:length(testd)){
      counter <- sleep(counter)
      test[[k]] <- as.data.frame(fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",testd[k])))
    }
    r <- 1
    b <- b_list[[1]]
    codes <- codes_list[[1]]
    agreg <- agreg_list[[1]]
    desag <- desag_v[1]
    # geo_ref_df <- geo_ref[[1]]
    geo_ref_by <- geo_ref_by_v[1]
    while("Falso" %in% colnames(test[[r]]$Sucesso)){
      r <- r + 1
      b <- b_list[[r]]
      codes <- codes_list[[r]]
      agreg <- agreg_list[[r]]
      desag <- desag_v[r]
      # geo_ref_df <- geo_ref[[r]]
      geo_ref_by <- geo_ref_by_v[r]
    }
    for (w in 1:b){
      counter <- sleep(counter)
      result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, codes[w],"&lang=PT"))
      dados <- as.data.frame(result$Dados)
      colunas_nanos <- colnames(dados)
      num_colunas <- length(colunas_nanos)
      if(obs_back > num_colunas){
        x <-num_colunas
      }else{
        x <-obs_back
      }
      # Get column names for years of interest
      obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
      df_all <- data.frame()
      # Loop over years
      for (obs in obs_cols) {
        # Remove all columns except current year
        df <- dados %>%
          unnest(!!sym(obs))%>%
          select(-any_of(colunas_nanos))%>%
          mutate(obs=as.character(obs))%>%
          left_join(largest_area, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
        # Add data frame to list
        df_all <- bind_rows(df_all, df)
        # Pause for 1 second
        Sys.sleep(1)
      }
      if(w==1){
        result_list[[indicador_atual]] <- df_all
      }
      else{
        result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
      }
      # return(result_list)
    }
  }
  # return(result_list)
# }  
result_list

# result_list <- ine.get(indicador,largest,obs_back,result_list)

#Freguesia
#Municipio
desag <- seq(1:20)
names(desag)
#NUTS2002
#NUTSI ou padrao
colnames(geolinkage_aces)
colnames(geolinkage_aces[2:20])
```

```{r}
result_list <- list()
largest_area <- geolinkage_aces %>%
  filter(aces_2022=="ACES Baixo Mondego")

geo_ref_df <- list(largest_area,largest_area[2:20],largest_area[2:20],largest_area[c(7:20)],largest_area[c(7:20)],largest_area[c(10:15,19,20)],largest_area[c(12:15)])

indicadores <- "0008614"
obs_back <- 2
largest_area <- geolinkage_aces %>%
  filter(aces_2022=="ACES Baixo Mondego")

# ine.get <- function(indicadores,largest_area,obs_back,result_list) {
  a <- length(indicadores)
  dicofre_2013 <- unique(largest_area$dicofre_2013)
  municipio_2013 <- unique(largest_area$municipio_2013_cod)
  municipio_2002 <- unique(largest_area$municipio_2002_cod)
  nuts_3_2013 <- unique(largest_area$nuts3_2013_cod)
  nuts_3_2002 <- unique(largest_area$nuts3_2002_cod)
  nuts_2_2013 <- unique(largest_area$nuts2_2013_cod)
  nuts_1 <- unique(largest_area$nuts1_2013_cod)
  counter <- 0
  #Existem 2 desagregacoes que estao hard-coded porque sao iguais entre 2013 e 2002
  testd <- c("&Dim2=11102&lang=PT",  #Testa a desagregação por freguesias
             "&Dim2=16E0111&lang=PT",#Testa a desagregação por municipio 2013
             "&Dim2=1610111&lang=PT",#Testa a desagregação por municipio 2002
             "&Dim2=16E&lang=PT",    #Testa a desagregação por NUTSIII 2013
             "&Dim2=161&lang=PT",    #Testa a desagregação por NUTSIII 2002
             "&Dim2=16&lang=PT",     #Testa a desagregação por NUTSII 2013
             "&lang=PT"                      #Testa a desagregação por NUTSI ou sem padrão 
  )
  codes_list <- list(dicofre_2013,municipio_2013,municipio_2002,nuts_3_2013,nuts_3_2002,nuts_2_2013,"")
  b_list <- list(length(dicofre_2013),length(municipio_2013),length(municipio_2002),length(nuts_3_2013),length(nuts_3_2002),length(nuts_2_2013),1)
  agreg_list <- list("Freguesia","Municipio","Municipio","NUTSIII","NUTSIII","NUTSII","Nacional")
  desag_v <- c("&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","")
  geo_ref_df <- list(largest_area,largest_area[2:20],largest_area[2:20],largest_area[c(7:20)],largest_area[c(7:20)],largest_area[c(10:15,19,20)],largest_area[c(12:15)])
  geo_ref_by_v <- c("dicofre_2013",
                    "municipio_2013_cod",
                    "municipio_2002_cod",
                    "nuts3_2013_cod",
                    "nuts3_2002_cod",
                    "nuts2_2013_cod",
                    "nuts1_2013_cod")
  for (i in 1:a) {
    #COMECA POR LER O INDICADOR A RETIRAR
    indicador_atual <- indicadores[i]
    counter <- sleep(counter)
    test <- list()
    for (k in 1:length(testd)){
      counter <- sleep(counter)
      test[[k]] <- as.data.frame(fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",testd[k])))
    }
    r <- 1
    b <- b_list[[1]]
    codes <- codes_list[[1]]
    agreg <- agreg_list[[1]]
    desag <- desag_v[1]
    geo_ref_df <- geo_ref_df[[1]]
    geo_ref_by <- geo_ref_by_v[1]
    while("Falso" %in% colnames(test[[r]]$Sucesso)){
      r <- r + 1
      b <- b_list[[r]]
      codes <- codes_list[[r]]
      agreg <- agreg_list[[r]]
      desag <- desag_v[r]
      geo_ref_df <- geo_ref_df[[r]]
      geo_ref_by <- geo_ref_by_v[r]
    }
    for (w in 1:b){
      counter <- sleep(counter)
      result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, codes[w],"&lang=PT"))
      dados <- as.data.frame(result$Dados)
      colunas_nanos <- colnames(dados)
      num_colunas <- length(colunas_nanos)
      if(obs_back > num_colunas){
        x <-num_colunas
      }else{
        x <-obs_back
      }
      # Get column names for years of interest
      obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
      df_all <- data.frame()
      # Loop over years
      for (obs in obs_cols) {
        # Remove all columns except current year
        df <- dados %>%
          unnest(!!sym(obs))%>%
          select(-any_of(colunas_nanos))%>%
          mutate(obs=as.character(obs))%>%
          left_join(geo_ref_df, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
        # Add data frame to list
        df_all <- bind_rows(df_all, df)
        # Pause for 1 second
        Sys.sleep(1)
      }
      if(w==1){
        result_list[[indicador_atual]] <- df_all
      }
      else{
        result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
      }
    }
  }
  return(result_list)
# }

result_list <- ine.get(indicador,largest,obs_back,result_list)
```
# New test
```{r}
geo_lookup <-
  read_csv(
    "datasets/geolinkage_aces_2022.csv",
    col_types = cols(.default = "c"),
    locale = locale("pt")
  )
# Remove `unknown` and `abroad` from the reference table
geo_lookup <- geo_lookup |>
  filter(!dicofre_2013 %in% c("0", "999999"))
# What data should be bound in the end?
geo_reference <- list(
  freguesia_2013 = geo_lookup,
  municipio_2013 = geo_lookup[3:20],
  municipio_2002 = geo_lookup[3:20],
  nuts3_2013 = geo_lookup[c(8:20)],
  nuts3_2002 = geo_lookup[c(8:20)],
  nuts2_2013 = geo_lookup[c(11:20)],
  nuts1_2013 = geo_lookup[c(13:20)],
  pais = geo_lookup[c(15:20)],
  total = geo_lookup,
  aces_2022 = geo_lookup[c(3:5, 8:20)],
  ars_2022 = geo_lookup[c(3:5, 11:20)]
)
# Retrieve the available indicators
indicators <- read_excel("datasets/Indicadores.xlsx",
  # col_types = cols(.default = "c"),
  skip = 14
) |>
  clean_names() |>
  filter(disponivel_no_portal == "Sim") |>
  distinct(designacao, .keep_all = TRUE)
# Prepare an empty list for the results
result_list <- list()
meta_list <- list()
# Sleep function to prevent server lockout, rests for 5 seconds every 100 requests
sleep <- function(z) {
  if (z %% 100 == 0) {
    Sys.sleep(5)
    z <- 1
  } else {
    z <- z + 1
  }
  return(z)
}


ine.get <- function(indicators,selected_areas,observation_requested, result_list, geo_reference,groups_chosen, groups_other) {
    # Set the sleep timer to 0
    counter <- 0
    # Save the selected areas' codes into vectors
    dicofre_2013 <- unique(selected_areas$dicofre_2013)
    municipio_2013 <- unique(selected_areas$municipio_2013_cod)
    municipio_2002 <- unique(selected_areas$municipio_2002_cod)
    nuts_3_2013 <- unique(selected_areas$nuts3_2013_cod)
    nuts_3_2002 <- unique(selected_areas$nuts3_2002_cod)
    nuts_2_2013 <- unique(selected_areas$nuts2_2013_cod)
    nuts_1_2013 <- unique(selected_areas$nuts1_2013_cod)
    pais <- unique(selected_areas$pais_cod)
    # Joins the code vectors in a list
    codes_reference <- list(
      dicofre_2013,
      municipio_2013,
      municipio_2002,
      nuts_3_2013,
      nuts_3_2002,
      nuts_2_2013,
      nuts_1_2013,
      pais,
      ""
    )
    # Joins the dimension strings in a list
    dimmension_reference <- c(
      "&Dim2=",
      "&Dim2=",
      "&Dim2=",
      "&Dim2=",
      "&Dim2=",
      "&Dim2=",
      "&Dim2=",
      "&Dim2=",
      ""
    )
    # Joins the col_names strings in a list
    level_names_reference <- c(
      "dicofre_2013",
      "municipio_2013_cod",
      "municipio_2002_cod",
      "nuts3_2013_cod",
      "nuts3_2002_cod",
      "nuts2_2013_cod",
      "nuts1_2013_cod",
      "pais_cod",
      ""
    )
    # Set the codes to test - one parish/municipality/NUTS III that changed codes between 2002 and 2013
    level_test <- c(
      # Tests parishes
      "&Dim2=011102&lang=PT",
      # Tests 2013 municipalities
      "&Dim2=16E0111&lang=PT",
      # Tests 2002 municipalities
      "&Dim2=1610111&lang=PT",
      # Tests 2013 NUTS III
      "&Dim2=16E&lang=PT",
      # Tests 2002 NUTS III
      "&Dim2=161&lang=PT",
      # Tests NUTS II
      "&Dim2=16&lang=PT",
      # Tests NUTS II
      "&Dim2=1&lang=PT",
      # Tests country
      "&Dim2=PT&lang=PT"
    )
    
    for (i in 1:length(indicators)) {
      # Get the current indicator
      indicators_current <- indicators[i]
      result_list[[indicators_current]] <- data.frame()
      # Call the sleep function
      counter <- sleep(counter)
      # Prepare an empty list for the test
      test <- list()
      # Call the INE API to test the different codes and stores the results in a list of tibbles
      for (j in 1:length(level_test)) {
        counter <- sleep(counter)
        test[[j]] <-
          as.data.frame(fromJSON(
            paste0(
              "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
              indicators_current,
              "&Dim1=T",
              level_test[j]
            )
          ))
      }
      if (!is.null(groups_chosen) & !is.null(groups_other)) {
        groups_chosen <- c(groups_chosen, groups_other)
      }
      success <- c(10)
      for (k in 1:length(groups_chosen)) {
        # Set starting level
        l <- case_when(
          groups_chosen[k] == "Freguesia" ~ 1,
          groups_chosen[k] == "Município" ~ 2,
          groups_chosen[k] == "Distrito" ~ 2,
          groups_chosen[k] == "NUTS III" ~ 4,
          groups_chosen[k] == "NUTS II" ~ 6,
          groups_chosen[k] == "NUTS I" ~ 7,
          groups_chosen[k] == "País" ~ 8,
          groups_chosen[k] == "ACES" ~ 1,
          groups_chosen[k] == "ARS" ~ 2,
          # If all others fail, the default is the parish level
          TRUE ~ 1
        )
        # Sets the chosen values from the starting level
        codes_chosen <- codes_reference[[l]]
        dimmension_chosen <- dimmension_reference[l]
        geo_chosen <- geo_reference[[l]]
        level_names_chosen <- level_names_reference[l]
        # If it fails, then it increments until it finds a level with data
        while (!(("Falso" %in% colnames(test[[l]]$Sucesso)) && l < 9)) {
          l <- l + 1
          if (l > 8) {
          codes_chosen <- codes_reference[[9]]
          dimmension_chosen <- dimmension_reference[9]
          geo_chosen <- geo_reference[[9]]
          level_names_chosen <- level_names_reference[9]
            errorCondition("Condições selecionadas sem resultados para este indicador.")
            next
          }
          codes_chosen <- codes_reference[[l]]
          dimmension_chosen <- dimmension_reference[l]
          geo_chosen <- geo_reference[[l]]
          level_names_chosen <- level_names_reference[l]
          # Error condition when none of the selected levels have data
        }
        # If the level we want was already retrieved, jump to the next `groups_chosen`
        if (l %in% success) {
          next
        } else {
          # Set an empty result data frame for all codes in each level
          df_all <- data.frame()
          # It increments along the codes
          for (m in 1:length(codes_chosen)) {
            # Call the sleep function
            counter <- sleep(counter)
            # Call the INE API to gather the datasets for each code
            results_raw <-
              fromJSON(
                paste0(
                  "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
                  indicators_current,
                  "&Dim1=T",
                  dimmension_chosen,
                  codes_chosen[m],
                  "&lang=PT"
                )
              )
            if( "Falso" %in% colnames(results_raw[]$Sucesso) ){
              success <- sort(c(success, l))
              next
            }
            # Extracts the data from  the INE API response
            results <- as.data.frame(results_raw$Dados)
            observation_available_names <- colnames(results)
            observation_available <- length(observation_available_names)
            # Checks if the requested number of observations is available
            if (observation_requested > observation_available) {
              observation_used <- observation_available
            } else {
              observation_used <- observation_requested
            }
            # Get names of the observations of interest
            observation_used_names <- c(observation_available_names[(observation_available - observation_used + 1):(observation_available)])
            # Set an empty result data frame for all observations in each code
            df_observations <- data.frame()
            # Loop over observations
            for (observation_current in observation_used_names) {
              # Remove everything except the observations we want
              df <- results |>
                unnest(!!sym(observation_current)) |>
                select(-any_of(observation_available_names)) |>
                mutate(
                  obs = as.character(observation_current),
                  valor = as.numeric(valor)
                )
              # Add results to data frame for all observations in each code
              df_observations <- bind_rows(df_observations, df)
            }
          # Add results to data frame for all codes in each level
          df_all <- bind_rows(df_observations, df_all)
            
          # If only one level and code were requested, it outputs the results directly
          if (k == 1 & m == 1) {
            result_list[[indicators_current]] <- df_all
          } else {
            # If more than one group OR code were requested, it adds the results to the existing ones
            result_list[[indicators_current]] <-
              bind_rows(result_list[[indicators_current]], df_all) |>
              unique()
          }
          # Adds the group we retrieved to the list
          success <- sort(c(success, l))
          }
        }
        # Runs the synthetic groups if requested and possible
        if (any(c("Distrito", "ACES", "ARS") %in% groups_chosen) & min(success) < 4) {
          if (1 %in% success) {
            level_names_success <- level_names_reference[1]
          } else if (2 %in% success) {
            level_names_success <- level_names_reference[2]
          } else if (3 %in% success) {
            level_names_success <- level_names_reference[3]
          }
          if ("Distrito" %in% groups_chosen) {
            if(any(str_detect(colnames(result_list[[indicators_current]]), "dim"))){
              if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 2){
                result_list[[indicators_current]] <- bind_rows(
                  result_list[[indicators_current]],
                  result_list[[indicators_current]] |>
                    # Adds the geographical information
                    left_join(geo_chosen,
                              by = c("geocod" = as.character(level_names_success)),
                              multiple = "first"
                    ) |>
                    # Groups the results
                    summarise(
                      geocod = distrito_2013_cod,
                      geodsg = distrito_2013,
                      valor = sum(valor,na.rm=TRUE),
                      # obs = obs,
                      .by = c(obs, distrito_2013, dim_3, dim_3_t)) |>
                    select(geocod, geodsg, dim_3, dim_3_t, valor, obs) |>
                    unique()
                )}else if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 4){
                  result_list[[indicators_current]] <- bind_rows(
                    result_list[[indicators_current]],
                    result_list[[indicators_current]] |>
                      # Adds the geographical information
                      left_join(geo_chosen,
                                by = c("geocod" = as.character(level_names_success)),
                                multiple = "first"
                      ) |>
                      # Groups the results
                      summarise(
                        geocod = distrito_2013_cod,
                        geodsg = distrito_2013,
                        valor = sum(valor,na.rm=TRUE),
                        # obs = obs,
                        .by = c(obs, distrito_2013, dim_3, dim_3_t, dim_4, dim_4_t)) |>
                      select(geocod, geodsg,dim_3, dim_3_t, dim_4, dim_4_t, valor, obs) |>
                      unique())}
              else if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 6){
                result_list[[indicators_current]] <- bind_rows(
                  result_list[[indicators_current]],
                  result_list[[indicators_current]] |>
                    # Adds the geographical information
                    left_join(geo_chosen,
                              by = c("geocod" = as.character(level_names_success)),
                              multiple = "first"
                    ) |>
                    # Groups the results
                    summarise(
                      geocod = distrito_2013_cod,
                      geodsg = distrito_2013,
                      valor = sum(valor,na.rm=TRUE),
                      # obs = obs,
                      .by = c(obs, distrito_2013, dim_3, dim_3_t, dim_4, dim_4_t, dim_5, dim_5_t)) |>
                    select(geocod, geodsg,dim_3, dim_3_t, dim_4, dim_4_t, dim_5, dim_5_t, valor, obs) |>
                    unique())}
            }else{ result_list[[indicators_current]] <- bind_rows(
              result_list[[indicators_current]],
              result_list[[indicators_current]] |>
                # Adds the geographical information
                left_join(geo_chosen,
                          by = c("geocod" = as.character(level_names_success)),
                          multiple = "first"
                ) |>
                # Groups the results
                summarise(
                  geocod = distrito_2013_cod,
                  geodsg = distrito_2013,
                  valor = sum(valor,na.rm=TRUE),
                  # obs = obs,
                  .by = c(obs, distrito_2013)) |>
                # select(geocod, geodsg, valor, obs) |>
                unique())}
          } else if ("ACES" %in% groups_chosen) {
            if(any(str_detect(colnames(result_list[[indicators_current]]), "dim"))){
              if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 2){
                result_list[[indicators_current]] <- bind_rows(
                  result_list[[indicators_current]],
                  result_list[[indicators_current]] |>
                    # Adds the geographical information
                    left_join(geo_chosen,
                              by = c("geocod" = as.character(level_names_success)),
                              multiple = "first"
                    ) |>
                    # Groups the results
                    summarise(
                      geocod = aces_2022_cod,
                      geodsg = aces_2022,
                      valor = sum(valor, na.rm = TRUE),
                      # obs = obs,
                      .by = c(obs, aces_2022, dim_3, dim_3_t)
                    ) |>
                    select(geocod, geodsg, dim_3, dim_3_t, valor, obs) |>
                    unique()
                )}else if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 4){
                  result_list[[indicators_current]] <- bind_rows(
                    result_list[[indicators_current]],
                    result_list[[indicators_current]] |>
                      # Adds the geographical information
                      left_join(geo_chosen,
                                by = c("geocod" = as.character(level_names_success)),
                                multiple = "first"
                      ) |>
                      # Groups the results
                      summarise(
                        geocod = aces_2022_cod,
                        geodsg = aces_2022,
                        valor = sum(valor, na.rm = TRUE),
                        # obs = obs,
                        .by = c(obs, aces_2022, dim_3, dim_3_t, dim_4, dim_4_t)
                      ) |>
                      select(geocod, geodsg,dim_3, dim_3_t, dim_4, dim_4_t, valor, obs) |>
                      unique())}
              else if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 6){
                result_list[[indicators_current]] <- bind_rows(
                  result_list[[indicators_current]],
                  result_list[[indicators_current]] |>
                    # Adds the geographical information
                    left_join(geo_chosen,
                              by = c("geocod" = as.character(level_names_success)),
                              multiple = "first"
                    ) |>
                    # Groups the results
                    summarise(
                      geocod = aces_2022_cod,
                      geodsg = aces_2022,
                      valor = sum(valor, na.rm = TRUE),
                      # obs = obs,
                      # .by = c(obs, aces_2022)
                      .by = c(obs, aces_2022, dim_3, dim_3_t, dim_4, dim_4_t, dim_5, dim_5_t)
                    ) |>
                    select(geocod, geodsg,dim_3, dim_3_t, dim_4, dim_4_t, dim_5, dim_5_t, valor, obs) |>
                    unique())}
            }else{ result_list[[indicators_current]] <- bind_rows(
              result_list[[indicators_current]],
              result_list[[indicators_current]] |>
                # Adds the geographical information
                left_join(geo_chosen,
                          by = c("geocod" = as.character(level_names_success)),
                          multiple = "first"
                ) |>
                # Groups the results
                summarise(
                  geocod = aces_2022_cod,
                  geodsg = aces_2022,
                  valor = sum(valor, na.rm = TRUE),
                  # obs = obs,
                  .by = c(obs, aces_2022)
                ) |>
                dplyr::select(geocod, geodsg, valor, obs) |>
                unique())}
          } else if ("ARS" %in% groups_chosen) {
            if(any(str_detect(colnames(result_list[[indicators_current]]), "dim"))){
              if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 2){
                result_list[[indicators_current]] <- bind_rows(
                  result_list[[indicators_current]],
                  result_list[[indicators_current]] |>
                    # Adds the geographical information
                    left_join(geo_chosen,
                              by = c("geocod" = as.character(level_names_success)),
                              multiple = "first"
                    ) |>
                    # Groups the results
                    summarise(
                      geocod = ars_2022_cod,
                      geodsg = ars_2022,
                      valor = sum(valor, na.rm=TRUE),
                      # obs = obs,
                      .by = c(obs, ars_2022, dim_3, dim_3_t)) |>
                    select(geocod, geodsg, dim_3, dim_3_t, valor, obs) |>
                    unique()
                )}else if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 4){
                  result_list[[indicators_current]] <- bind_rows(
                    result_list[[indicators_current]],
                    result_list[[indicators_current]] |>
                      # Adds the geographical information
                      left_join(geo_chosen,
                                by = c("geocod" = as.character(level_names_success)),
                                multiple = "first"
                      ) |>
                      # Groups the results
                      summarise(
                        geocod = ars_2022_cod,
                        geodsg = ars_2022,
                        valor = sum(valor, na.rm=TRUE),
                        # obs = obs,
                        .by = c(obs, ars_2022, dim_3, dim_3_t, dim_4, dim_4_t)) |>
                      select(geocod, geodsg,dim_3, dim_3_t, dim_4, dim_4_t, valor, obs) |>
                      unique())}
              else if(sum(str_detect(colnames(result_list[[indicators_current]]), "dim"))== 6){
                result_list[[indicators_current]] <- bind_rows(
                  result_list[[indicators_current]],
                  result_list[[indicators_current]] |>
                    # Adds the geographical information
                    left_join(geo_chosen,
                              by = c("geocod" = as.character(level_names_success)),
                              multiple = "first"
                    ) |>
                    # Groups the results
                    summarise(
                      geocod = ars_2022_cod,
                      geodsg = ars_2022,
                      valor = sum(valor, na.rm=TRUE),
                      # obs = obs,
                      .by = c(obs, ars_2022, dim_3, dim_3_t, dim_4, dim_4_t, dim_5, dim_5_t)) |>
                    select(geocod, geodsg,dim_3, dim_3_t, dim_4, dim_4_t, dim_5, dim_5_t, valor, obs) |>
                    unique())}
            }else{ result_list[[indicators_current]] <- bind_rows(
              result_list[[indicators_current]],
              result_list[[indicators_current]] |>
                # Adds the geographical information
                left_join(geo_chosen,
                          by = c("geocod" = as.character(level_names_success)),
                          multiple = "first"
                ) |>
                # Groups the results
                # Groups the results
                summarise(
                  geocod = ars_2022_cod,
                  geodsg = ars_2022,
                  valor = sum(valor, na.rm=TRUE),
                  # obs = obs,
                  .by = c(obs, ars_2022)) |>
                select(geocod, geodsg, valor, obs) |>
                unique())}
          }
        }
      }
      if(!"valor" %in% colnames(result_list[[indicators_current]])){
        result_list[[indicators_current]] <- data.frame(geocod=0, geodsg=0, valor=0,obs=0, year=0)
      }
      }
    return(result_list)
}

filtered <-
      geo_lookup |> filter("Portugal" %in% pais)

geo_reference <- list(
  freguesia_2013 = geo_lookup,
  municipio_2013 = geo_lookup[3:20],
  municipio_2002 = geo_lookup[3:20],
  nuts3_2013 = geo_lookup[c(8:20)],
  nuts3_2002 = geo_lookup[c(8:20)],
  nuts2_2013 = geo_lookup[c(11:20)],
  nuts1_2013 = geo_lookup[c(13:20)],
  pais = geo_lookup[c(15:20)],
  total = geo_lookup,
  aces_2022 = geo_lookup[c(3:5, 8:20)],
  ars_2022 = geo_lookup[c(3:5, 11:20)]
)

result_list_updated <- ine.get(
  indicators = c("0008460")
  ,selected_areas = filtered
  ,observation_requested = c(1)
  ,result_list = result_list
  ,geo_reference = geo_reference
  ,groups_chosen = "País"
  ,groups_other = NULL)

level_test <- c(
      # Tests parishes
      "&Dim2=011102&lang=PT",
      # Tests 2013 municipalities
      "&Dim2=16E0111&lang=PT",
      # Tests 2002 municipalities
      "&Dim2=1610111&lang=PT",
      # Tests 2013 NUTS III
      "&Dim2=16E&lang=PT",
      # Tests 2002 NUTS III
      "&Dim2=161&lang=PT",
      # Tests NUTS II
      "&Dim2=16&lang=PT",
      # Tests NUTS II
      "&Dim2=1&lang=PT",
      # Tests country
      "&Dim2=PT&lang=PT"
    )

test <-
          as.data.frame(fromJSON(
            paste0(
              "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
              "0008460",
              "&Dim1=T",
              "&Dim2=PT&lang=PT"
            )
          ))

      # Get the current indicator
      indicators_current <- "0008460"
      result_list[[indicators_current]] <- data.frame()
      # Call the sleep function
      # counter <- sleep(counter)
      # Prepare an empty list for the test
      test <- list()
      # Call the INE API to test the different codes and stores the results in a list of tibbles
      for (j in 1:length(level_test)) {
        # counter <- sleep(counter)
        test[[j]] <-
          as.data.frame(fromJSON(
            paste0(
              "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
              indicators_current,
              "&Dim1=T",
              level_test[j]
            )
          ))
      }
```
####Theme extractor
```{r}
install.packages("XML")
install.packages("methods")
install.packages("xml2")
library(methods)
library(XML)
library(xml2)
test <-
          as.data.frame(fromJSON(
            paste0(
              "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
              "0008460",
              "&Dim1=T",
              "&Dim2=PT&lang=PT"
            )
          ))

      # Get the current indicator
      indicators_current <- "0008460"
      result_list[[indicators_current]] <- data.frame()
      # Call the sleep function
      # counter <- sleep(counter)
      # Prepare an empty list for the test
      test <- list()
      # Call the INE API to test the different codes and stores the results in a list of tibbles
      for (j in 1:length(level_test)) {
        # counter <- sleep(counter)
        test[[j]] <-
          as.data.frame(fromJSON(
            paste0(
              "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
              indicators_current,
              "&Dim1=T",
              level_test[j]
            )
          ))
      }
test <- results_raw <- fromJSON(
      paste0(
        "https://www.ine.pt/ine/json_indicador/pindicaMeta.jsp?varcd=",
        "0008460",
        "&lang=PT"
      ))


xml <- xmlToDataFrame("https://www.ine.pt/ine/xml_indic.jsp?opc=2&lang=PT")


xml_data <- xmlParse("INE_API/datasets/ine.xml")
xml_structure(xml)
indicator <- xml_text(xml_find_all(xml_data, ".//theme"))

xml_data <- xmlParse("INE_API/datasets/final_ine.xml")
```

```{r}
install.packages("xml2")
library(xml2)

url <- "https://www.ine.pt/ine/xml_indic.jsp?opc=2&lang=PT"

# Set the path to save the downloaded file
file_path <- "path_to_save/file.xml"
# Replace "path_to_save/file.xml" with the desired path and filename for the downloaded file

# Download the XML file
download.file(url, destfile = file_path, mode = "wb")

# Read the downloaded XML file
xml_file <- read_xml(file_path)
xml_file <- read_xml("INE_API/datasets/final_ine.xml")
# Access the root node
root_node <- xml_root(xml_file)

# Access child nodes
child_nodes <- xml_children(root_node)

# Access attributes of a node
attributes <- xml_attrs(root_node)


node_values <- xml_text(xml_find_all(xml_file, "//node_name"))

# testxml <- xmlParse("INE_API/datasets/final_ine.xml")
# 
# dataframe <-xmlToDataFrame(xml_file)
theme <- xml_text(xml_find_all(xml_file, "//node_name"))
library(xml2)

# Read the XML data
xml_file <- read_xml("INE_API/datasets/final_ine.xml")

# Extract values from XML nodes
extraction_date <- xml_text(xml_find_all(xml_file, "//extraction_date"))
source <- xml_text(xml_find_all(xml_file, "//source"))
theme <- xml_text(xml_find_all(xml_file, "//theme"))
subtheme <- xml_text(xml_find_all(xml_file, "//subtheme"))
keywords <- xml_text(xml_find_all(xml_file, "//keywords"))
title <- xml_text(xml_find_all(xml_file, "//title"))
varcd <- xml_text(xml_find_all(xml_file, "//varcd"))
description <- xml_text(xml_find_all(xml_file, "//description"))
geo_lastlevel <- xml_text(xml_find_all(xml_file, "//geo_lastlevel"))
first_period_available <- xml_text(xml_find_all(xml_file, "//first_period_available"))
last_period_available <- xml_text(xml_find_all(xml_file, "//last_period_available"))
last_update <- xml_text(xml_find_all(xml_file, "//last_update"))
periodicity <- xml_text(xml_find_all(xml_file, "//periodicity"))
update_type <- xml_text(xml_find_all(xml_file, "//update_type"))
bdd_url <- xml_text(xml_find_all(xml_file, "//bdd_url"))
metainfo_url <- xml_text(xml_find_all(xml_file, "//metainfo_url"))
json_dataset <- xml_text(xml_find_all(xml_file, "//json_dataset"))
json_metainfo <- xml_text(xml_find_all(xml_file, "//json_metainfo"))

# Create a dataframe
source
extraction_date 
theme, 
subtheme,
df <- data.frame( keywords, title, varcd, description,
                 geo_lastlevel, first_period_available, last_period_available, last_update,
                 periodicity, update_type, bdd_url, metainfo_url, json_dataset, json_metainfo)

# Print the dataframe
print(df)


```

#Final Catalog extractor
```{r}
url <- "https://www.ine.pt/ine/xml_indic.jsp?opc=2&lang=PT"

# Set the path to save the downloaded file
file_path <- "INE_API/datasets/final_ine.xml"

# Replace "path_to_save/file.xml" with the desired path and filename for the downloaded file

# Download the XML file
download_xml(url, file = file_path, mode = "wb")

# Read the downloaded XML file
xml_file <- read_xml(file_path)


get_node_values <- function(nodes) {
  if (length(nodes) > 0) {
    return(xml_text(nodes))
  } else {
    return(NA)
  }
}

# Extract values from XML nodes
extraction_date <- get_node_values(xml_find_first(xml_file, "//extraction_date"))

source <- get_node_values(xml_find_first(xml_file, "//source"))


themes <- xml_find_all(xml_file, "//theme")
theme <- sapply(themes, function(node) {
  theme_text <- xml_text(node)
  if (length(theme_text) > 0) {
    return(theme_text[1])
  } else {
    return(NA)
  }
})

subthemes <- xml_find_all(xml_file, "//subtheme")
subtheme <- sapply(subthemes, function(node) {
  subtheme_text <- xml_text(node)
  if (length(subtheme_text) > 0) {
    return(subtheme_text[1])
  } else {
    return(NA)
  }
})

# Extract values from XML nodes
extraction_date <- get_node_values(xml_find_first(xml_file, "//extraction_date"))

source <- get_node_values(xml_find_first(xml_file, "//source"))

# themes <- xml_find_all(xml_file, "//theme" , flatten = FALSE)
# subthemes <- xml_find_all(xml_file, "//subtheme", flatten = FALSE)
# theme <- get_node_values(xml_find_all(xml_file, "//theme"))
# subtheme <- get_node_values(xml_find_all(xml_file, "//subtheme"))
keywords <- get_node_values(xml_find_all(xml_file, "//keywords"))
title <- get_node_values(xml_find_all(xml_file, "//title"))
varcd <- get_node_values(xml_find_all(xml_file, "//varcd"))
description <- get_node_values(xml_find_all(xml_file, "//description"))
geo_lastlevel <- get_node_values(xml_find_all(xml_file, "//geo_lastlevel"))
first_period_available <- get_node_values(xml_find_all(xml_file, "//first_period_available"))
last_period_available <- get_node_values(xml_find_all(xml_file, "//last_period_available"))
last_update <- get_node_values(xml_find_all(xml_file, "//last_update"))
periodicity <- get_node_values(xml_find_all(xml_file, "//periodicity"))
update_type <- get_node_values(xml_find_all(xml_file, "//update_type"))
bdd_url <- get_node_values(xml_find_all(xml_file, "//bdd_url"))
metainfo_url <- get_node_values(xml_find_all(xml_file, "//metainfo_url"))
json_dataset <- get_node_values(xml_find_all(xml_file, "//json_dataset"))
json_metainfo <- get_node_values(xml_find_all(xml_file, "//json_metainfo"))


extraction_date <- rep(c(extraction_date), each=length(description))
source <- rep(c(source), each=length(description))
# Create a dataframe
df <- data.table(extraction_date, source, theme, subtheme, keywords, title, varcd, description,
                 geo_lastlevel, first_period_available, last_period_available, last_update,
                 periodicity, update_type, bdd_url, metainfo_url, json_dataset, json_metainfo)

# Print the dataframe
print(df)

```

```{r}
library(xml2)
library(data.table)

# Read the XML data
xml_file <- read_xml("path_to_file.xml")

# Helper function to extract node value or return NA if the node doesn't exist
get_node_value <- function(node) {
  if (length(node) > 0) {
    return(xml_text(node))
  } else {
    return(NA)
  }
}

# Extract values from XML nodes
extraction_date <- get_node_value(xml_find_first(xml_file, "//extraction_date"))
source <- get_node_value(xml_find_first(xml_file, "//source"))

themes <- xml_find_all(xml_file, "//theme")
theme <- sapply(themes, function(node) {
  theme_text <- xml_text(node)
  if (length(theme_text) > 0) {
    return(theme_text[1])
  } else {
    return(NA)
  }
})

subthemes <- xml_find_all(xml_file, "//subtheme")
subtheme <- sapply(subthemes, function(node) {
  subtheme_text <- xml_text(node)
  if (length(subtheme_text) > 0) {
    return(subtheme_text[1])
  } else {
    return(NA)
  }
})

keywords <- get_node_value(xml_find_first(xml_file, "//keywords"))
title <- get_node_value(xml_find_first(xml_file, "//title"))
varcd <- get_node_value(xml_find_first(xml_file, "//varcd"))
description <- get_node_value(xml_find_first(xml_file, "//description"))
geo_lastlevel <- get_node_value(xml_find_first(xml_file, "//geo_lastlevel"))
first_period_available <- get_node_value(xml_find_first(xml_file, "//first_period_available"))
last_period_available <- get_node_value(xml_find_first(xml_file, "//last_period_available"))
last_update <- get_node_value(xml_find_first(xml_file, "//last_update"))
periodicity <- get_node_value(xml_find_first(xml_file, "//periodicity"))
update_type <- get_node_value(xml_find_first(xml_file, "//update_type"))
bdd_url <- get_node_value(xml_find_first(xml_file, "//bdd_url"))
metainfo_url <- get_node_value(xml_find_first(xml_file, "//metainfo_url"))
json_dataset <- get_node_value(xml_find_first(xml_file, "//json_dataset"))
json_metainfo <- get_node_value(xml_find_first(xml_file, "//json_metainfo"))

# Create a data.table
df <- data.table(extraction_date, source, theme, subtheme, keywords, title, varcd, description,
                 geo_lastlevel, first_period_available, last_period_available, last_update,
                 periodicity, update_type, bdd_url, metainfo_url, json_dataset, json_metainfo)

# Print the data.table
print(df)

```

```{r}
library(xml2)

# Helper function to extract node value or return NA if the node doesn't exist
get_node_value <- function(node) {
  if (length(node) > 0) {
    return(xml_text(node))
  } else {
    return(NA)
  }
}

# Extract indicator nodes
indicator_nodes <- xml_find_all(xml_file, "//indicator")

# Initialize lists to store indicator information
indicators <- list()
themes <- list()

# Iterate over indicator nodes and extract information
for (node in indicator_nodes) {
  indicator <- get_node_value(xml_find_first(node, ".//varcd"))
  theme <- get_node_value(xml_find_first(node, ".//theme"))
  
  indicators <- c(indicators, indicator)
  themes <- c(themes, theme)
}

# Create a data frame
df <- data.frame(indicator = unlist(indicators),
                 theme = unlist(themes))

# Print the data frame
print(df)

```

```{r}

restaurant_license_xml <-  as_list(xml_file)


xml_df <- tibble::as_tibble(restaurant_license_xml) %>%
  unnest_longer(catalog)

xml_wider <-  xml_df %>%
  dplyr::filter(DATA_id == "indicator") %>%
  unnest_wider(DATA) 

```

```{r}
library(xml2)

# Helper function to extract node value or return NA if the node doesn't exist
# get_node_value <- function(node) {
#   if (length(node) > 0) {
#     return(xml_text(node))
#   } else {
#     return(NA)
#   }
# }

# Extract indicator nodes
indicator_nodes <- xml_find_all(xml_file, "//indicator")

# Initialize lists to store indicator information
indicators <- list()
themes <- list()
subthemes <- list()

# Iterate over indicator nodes and extract information
for (node in indicator_nodes) {
  indicator <- 
     # get_node_value(
       xml_find_first(node, "./varcd")
  theme <- 
    # get_node_value(
      xml_find_first(node, "./theme")
  subtheme <- 
    # get_node_value(
    xml_find_first(node, "./subtheme")
  
  indicators <- c(indicators, indicator)
  themes <- c(themes, theme)
  subthemes <- c(subthemes, subtheme)
}

# Create a data frame
df <- data.frame(indicator = unlist(indicators),
                 theme = unlist(themes),
                 subtheme = unlist(subthemes))

# Print the data frame
print(df)

```
#### FINAL ONE
```{r}
library(xml2)

url <- "https://www.ine.pt/ine/xml_indic.jsp?opc=2&lang=PT"

# Set the path to save the downloaded file
file_path <- "INE_API/datasets/final_ine.xml"

# Replace "path_to_save/file.xml" with the desired path and filename for the downloaded file

# Download the XML file
download_xml(url, file = file_path, mode = "wb")

# Read the downloaded XML file
xml_file <- read_xml(file_path)

get_node_values <- function(nodes) {
  if (length(nodes) > 0) {
    return(xml_text(nodes))
  } else {
    return(NA)
  }
}

# restaurant_license_xml <-  as_list(xml_file)
# xml_df <- tibble::as_tibble(restaurant_license_xml) %>%
#   unnest_longer(catalog)


# Extract values from XML nodes
extraction_date <- get_node_values(xml_find_first(xml_file, "//extraction_date"))
source <- get_node_values(xml_find_first(xml_file, "//source"))
keywords <- get_node_values(xml_find_all(xml_file, "//keywords"))
title <- get_node_values(xml_find_all(xml_file, "//title"))
varcd <- get_node_values(xml_find_all(xml_file, "//varcd"))
description <- get_node_values(xml_find_all(xml_file, "//description"))
geo_lastlevel <- get_node_values(xml_find_all(xml_file, "//geo_lastlevel"))
first_period_available <- get_node_values(xml_find_all(xml_file, "//first_period_available"))
last_period_available <- get_node_values(xml_find_all(xml_file, "//last_period_available"))
last_update <- get_node_values(xml_find_all(xml_file, "//last_update"))
periodicity <- get_node_values(xml_find_all(xml_file, "//periodicity"))
update_type <- get_node_values(xml_find_all(xml_file, "//update_type"))
bdd_url <- get_node_values(xml_find_all(xml_file, "//bdd_url"))
metainfo_url <- get_node_values(xml_find_all(xml_file, "//metainfo_url"))
json_dataset <- get_node_values(xml_find_all(xml_file, "//json_dataset"))
json_metainfo <- get_node_values(xml_find_all(xml_file, "//json_metainfo"))
indicator_nodes <- xml_find_all(xml_file, "//indicator")


extraction_date <- rep(c(extraction_date), each=length(description))
source <- rep(c(source), each=length(description))

# for (node in indicator_nodes) {
#   theme <- 
#     # get_node_value(
#       xml_find_first(node, "./theme")
#   subtheme <- 
#     # get_node_value(
#       xml_find_first(node, "./subtheme")
#   
#   themes <- c(themes, theme)
#   subthemes <- c(subthemes, subtheme)
# }
# 
# theme <- unlist(themes)
# subtheme <- unlist(subthemes)
# Create a dataframe
# theme, 
# subtheme,

df <- data.table(extraction_date, source,  keywords, title, varcd, description,
                 geo_lastlevel, first_period_available, last_period_available, last_update,
                 periodicity, update_type, bdd_url, metainfo_url, json_dataset, json_metainfo)


# Print the dataframe
print(df)
```

```{r}
library(xml2)

url <- "https://www.ine.pt/ine/xml_indic.jsp?opc=2&lang=PT"

# Set the path to save the downloaded file
file_path <- "INE_API/datasets/final_ine.xml"

# Replace "path_to_save/file.xml" with the desired path and filename for the downloaded file

# Download the XML file
download_xml(url, file = file_path, mode = "wb")

# Read the downloaded XML file
xml_file <- read_xml(file_path)


# Helper function to extract node value or return NA if the node doesn't exist
get_node_value <- function(node, xpath) {
  target_node <- xml_find_first(node, xpath)
  if (!is.null(target_node)) {
    return(xml_text(target_node))
  } else {
    return(NA)
  }
}

# Extract indicator nodes
indicator_nodes <- xml_find_all(xml_file, "//indicator")

# Extract indicator information
indicators <- lapply(indicator_nodes, function(node) {
  data <- data.frame(
    theme = get_node_value(node, "./theme[1]"),
    subtheme = get_node_value(node, "./subtheme[1]"),
    keywords = get_node_value(node, "./keywords"),
    title = get_node_value(node, "./title"),
    varcd = get_node_value(node, "./varcd"),
    description = get_node_value(node, "./description"),
    geo_lastlevel = get_node_value(node, "./geo_lastlevel"),
    first_period_available = get_node_value(node, "./dates/first_period_available"),
    last_period_available = get_node_value(node, "./dates/last_period_available"),
    last_update = get_node_value(node, "./dates/last_update"),
    periodicity = get_node_value(node, "./periodicity"),
    update_type = get_node_value(node, "./update_type"),
    bdd_url = get_node_value(node, "./html/bdd_url"),
    metainfo_url = get_node_value(node, "./html/metainfo_url"),
    json_dataset = get_node_value(node, "./json/json_dataset"),
    json_metainfo = get_node_value(node, "./json/json_metainfo")
  )
  return(data)
})

# Combine indicator information into a single data frame
df <- do.call(rbind, indicators)

# Print the data frame
print(df)

library(data.table)
fwrite(
  df,
  file = "INE_API/datasets/final_ine.csv",
  sep = ";"
  , bom = TRUE
)


results_raw1 <-
              fromJSON(
                paste0(
                  "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
                  "0011626",
                  # "&Dim1=T",
                  # "&Dim2=",
                  # "PT",
                  "&lang=PT"
                )
              )


  paste0(
                  "https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",
                  "0011626",
                  # "&Dim1=T",
                  # "&Dim2=",
                  # "PT",
                  "&lang=PT"
                )

```

```{r}
results1 <- as.data.frame(results_raw1$Dados) |> unnest()
library(rio)
library(tidyverse)
export(results,"pop_muni_2022.csv",bom=TRUE)

codigos_df <- import("datasets/geo_linkage_2024_v2_1.csv", colClasses=c("character"))

codigosdf2 <- codigos_df |> 
  select(dicofre_2013,uls_2023)

dataset <- full_join(
  d3,codigosdf2, by= join_by("geocod"==dicofre_2013), multiple="all"
)

dataset$dim_4 <- as.numeric(dataset$dim_4)
dataset$valor <- as.numeric(dataset$valor)

teste <- dataset |> 
  filter(is.na(uls_2023))

dataset <- dataset |>
  filter(!is.na(dim_4)) |> 
  summarise(
    valor=sum(as.numeric(valor)),
    .by= c(uls_2023,dim_4,dim_3_t)
  )

dataset1 <- dataset |> 
  mutate(etario = case_when(
    dim_4 %in% gr_1 ~ "<1 ano"
    ,dim_4 %in% gr_2 ~ "1 - 4 anos"
    ,dim_4 %in% gr_3 ~ "5 - 9 anos"
    ,dim_4 %in% gr_4 ~ "10 - 14 anos"
    ,dim_4 %in% gr_5 ~ "15 - 19 anos"
    ,dim_4 %in% gr_6 ~ "20 - 24 anos"
    ,dim_4 %in% gr_7 ~ "25 - 29 anos"
    ,dim_4 %in% gr_8 ~ "30 - 34 anos"
    ,dim_4 %in% gr_9 ~ "35 - 39 anos"
    ,dim_4 %in% gr_10 ~ "40 - 44 anos"
    ,dim_4 %in% gr_11 ~ "45 - 49 anos"
    ,dim_4 %in% gr_12 ~ "50 - 54 anos"
    ,dim_4 %in% gr_13 ~ "55 - 59 anos"
    ,dim_4 %in% gr_14 ~ "60 - 64 anos"
    ,dim_4 %in% gr_15 ~ "65 - 69 anos"
    ,dim_4 %in% gr_16 ~ "70 - 74 anos"
    ,dim_4 %in% gr_17 ~ "75 - 80 anos"
     ,dim_4 %in% gr_18 ~ "81 - 84 anos"
     ,dim_4 %in% gr_19 ~ "85 e mais anos"
     # ,dim_4 %in% gr_20 ~ "Total"
   ))


dataset1 <- dataset1 |> 
  summarise(
    valor=sum(valor),
    .by= c(uls_2023,etario,dim_3_t)
  )

dataset1 <- dataset1 |> 
  arrange(uls_2023) |> 
  filter(dim_3_t!="HM")

dataset2 <- dataset1 |> 
  pivot_wider(
    id_cols = c(uls_2023,dim_3_t),
    names_from = etario,
    values_from = valor
  )

export(dataset2, "pop_uls_freg_2.csv", bom=T)

```

