# Get column names for years of interest
obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
df_all <- data.frame()
# Loop over years
for (obs in obs_cols) {
# Remove all columns except current year
df <- dados %>%
unnest(!!sym(obs))%>%
select(-any_of(colunas_nanos))%>%
mutate(obs=as.character(obs))%>%
left_join(largest_area, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
# Add data frame to list
df_all <- bind_rows(df_all, df)
# Pause for 1 second
Sys.sleep(1)
}
if(w==1){
result_list[[indicador_atual]] <- df_all
}
else{
result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
}
}
return(result_list)
}
return(result_list)
}
ine.get(indicador,largest,obs_back,result_list)
test <- list()
result_list <- list()
largest <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
indicador <- "0010247"
obs_back <- 2
result_list <- list()
largest_area <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
sleep <- function(z){
if (z %% 100 == 0) {
Sys.sleep(5)
z <- 1
}else{
z <- z+1
}
return(z)
}
ine.get <- function(indicadores,largest_area,obs_back,result_list) {
a <- length(indicadores)
dicofre_2013 <- unique(largest_area$dicofre_2013)
municipio_2013 <- unique(largest_area$municipio_2013_cod)
municipio_2002 <- unique(largest_area$municipio_2002_cod)
nuts_3_2013 <- unique(largest_area$nuts3_2013_cod)
nuts_3_2002 <- unique(largest_area$nuts3_2002_cod)
nuts_2_2013 <- unique(largest_area$nuts2_2013_cod)
nuts_1 <- unique(largest_area$nuts1_2013_cod)
counter <- 0
#Existem 2 desagregacoes que estao hard-coded porque sao iguais entre 2013 e 2002
testd <- c("&Dim2=11102&lang=PT",  #Testa a desagregação por freguesias
"&Dim2=16E0111&lang=PT",#Testa a desagregação por municipio 2013
"&Dim2=1610111&lang=PT",#Testa a desagregação por municipio 2002
"&Dim2=16E&lang=PT",    #Testa a desagregação por NUTSIII 2013
"&Dim2=161&lang=PT",    #Testa a desagregação por NUTSIII 2002
"&Dim2=16&lang=PT",     #Testa a desagregação por NUTSII 2013
"&lang=PT"                      #Testa a desagregação por NUTSI ou sem padrão
)
codes_list <- list(dicofre_2013,municipio_2013,municipio_2002,nuts_3_2013,nuts_3_2002,nuts_2_2013,"")
b_list <- list(length(dicofre_2013),length(municipio_2013),length(municipio_2002),length(nuts_3_2013),length(nuts_3_2002),length(nuts_2_2013),1)
agreg_list <- list("Freguesia","Municipio","Municipio","NUTSIII","NUTSIII","NUTSII","Nacional")
desag_v <- c("&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","")
# geo_ref_df <- list(dicofre_2013,municipio_2013_cod,municipio_2002_cod,nuts3_2013_codnuts3_2002_cod,nuts2_2013_cod,nuts_1)
geo_ref_by_v <- c("dicofre_2013",
"municipio_2013_cod",
"municipio_2002_cod",
"nuts3_2013_cod",
"nuts3_2002_cod",
"nuts2_2013_cod",
"nuts1_2013_cod")
for (i in 1:a) {
#COMECA POR LER O INDICADOR A RETIRAR
indicador_atual <- indicadores[i]
counter <- sleep(counter)
test <- list()
for (k in 1:length(test)){
counter <- sleep(counter)
test[[k]] <- as.data.frame(fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",testd[k])))
}
r <- 1
b <- b_list[[1]]
codes <- codes_list[[1]]
agreg <- agreg_list[[1]]
desag <- desag_v[1]
# geo_ref_df <- geo_ref[[1]]
geo_ref_by <- geo_ref_by_v[1]
while("Falso" %in% colnames(test[[r]]$Sucesso)){
r <- r + 1
b <- b_list[[r]]
codes <- codes_list[[r]]
agreg <- agreg_list[[r]]
desag <- desag_v[r]
# geo_ref_df <- geo_ref[[r]]
geo_ref_by <- geo_ref_by_v[r]
}
for (w in 1:b){
counter <- sleep(counter)
result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, codes[w],"&lang=PT"))
dados <- as.data.frame(result$Dados)
colunas_nanos <- colnames(dados)
num_colunas <- length(colunas_nanos)
if(obs_back > num_colunas){
x <-num_colunas
}else{
x <-obs_back
}
# Get column names for years of interest
obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
df_all <- data.frame()
# Loop over years
for (obs in obs_cols) {
# Remove all columns except current year
df <- dados %>%
unnest(!!sym(obs))%>%
select(-any_of(colunas_nanos))%>%
mutate(obs=as.character(obs))%>%
left_join(largest_area, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
# Add data frame to list
df_all <- bind_rows(df_all, df)
# Pause for 1 second
Sys.sleep(1)
}
if(w==1){
result_list[[indicador_atual]] <- df_all
}
else{
result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
}
}
return(result_list)
}
return(result_list)
}
ine.get(indicador,largest,obs_back,result_list)
result_list <- list()
largest <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
indicador <- "0010247"
obs_back <- 2
result_list <- list()
largest_area <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
sleep <- function(z){
if (z %% 100 == 0) {
Sys.sleep(5)
z <- 1
}else{
z <- z+1
}
return(z)
}
ine.get <- function(indicadores,largest_area,obs_back,result_list) {
a <- length(indicadores)
dicofre_2013 <- unique(largest_area$dicofre_2013)
municipio_2013 <- unique(largest_area$municipio_2013_cod)
municipio_2002 <- unique(largest_area$municipio_2002_cod)
nuts_3_2013 <- unique(largest_area$nuts3_2013_cod)
nuts_3_2002 <- unique(largest_area$nuts3_2002_cod)
nuts_2_2013 <- unique(largest_area$nuts2_2013_cod)
nuts_1 <- unique(largest_area$nuts1_2013_cod)
counter <- 0
#Existem 2 desagregacoes que estao hard-coded porque sao iguais entre 2013 e 2002
testd <- c("&Dim2=11102&lang=PT",  #Testa a desagregação por freguesias
"&Dim2=16E0111&lang=PT",#Testa a desagregação por municipio 2013
"&Dim2=1610111&lang=PT",#Testa a desagregação por municipio 2002
"&Dim2=16E&lang=PT",    #Testa a desagregação por NUTSIII 2013
"&Dim2=161&lang=PT",    #Testa a desagregação por NUTSIII 2002
"&Dim2=16&lang=PT",     #Testa a desagregação por NUTSII 2013
"&lang=PT"                      #Testa a desagregação por NUTSI ou sem padrão
)
codes_list <- list(dicofre_2013,municipio_2013,municipio_2002,nuts_3_2013,nuts_3_2002,nuts_2_2013,"")
b_list <- list(length(dicofre_2013),length(municipio_2013),length(municipio_2002),length(nuts_3_2013),length(nuts_3_2002),length(nuts_2_2013),1)
agreg_list <- list("Freguesia","Municipio","Municipio","NUTSIII","NUTSIII","NUTSII","Nacional")
desag_v <- c("&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","")
# geo_ref_df <- list(dicofre_2013,municipio_2013_cod,municipio_2002_cod,nuts3_2013_codnuts3_2002_cod,nuts2_2013_cod,nuts_1)
geo_ref_by_v <- c("dicofre_2013",
"municipio_2013_cod",
"municipio_2002_cod",
"nuts3_2013_cod",
"nuts3_2002_cod",
"nuts2_2013_cod",
"nuts1_2013_cod")
for (i in 1:a) {
#COMECA POR LER O INDICADOR A RETIRAR
indicador_atual <- indicadores[i]
counter <- sleep(counter)
test <- list()
for (k in 1:length(testd)){
counter <- sleep(counter)
test[[k]] <- as.data.frame(fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",testd[k])))
}
r <- 1
b <- b_list[[1]]
codes <- codes_list[[1]]
agreg <- agreg_list[[1]]
desag <- desag_v[1]
# geo_ref_df <- geo_ref[[1]]
geo_ref_by <- geo_ref_by_v[1]
while("Falso" %in% colnames(test[[r]]$Sucesso)){
r <- r + 1
b <- b_list[[r]]
codes <- codes_list[[r]]
agreg <- agreg_list[[r]]
desag <- desag_v[r]
# geo_ref_df <- geo_ref[[r]]
geo_ref_by <- geo_ref_by_v[r]
}
for (w in 1:b){
counter <- sleep(counter)
result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, codes[w],"&lang=PT"))
dados <- as.data.frame(result$Dados)
colunas_nanos <- colnames(dados)
num_colunas <- length(colunas_nanos)
if(obs_back > num_colunas){
x <-num_colunas
}else{
x <-obs_back
}
# Get column names for years of interest
obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
df_all <- data.frame()
# Loop over years
for (obs in obs_cols) {
# Remove all columns except current year
df <- dados %>%
unnest(!!sym(obs))%>%
select(-any_of(colunas_nanos))%>%
mutate(obs=as.character(obs))%>%
left_join(largest_area, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
# Add data frame to list
df_all <- bind_rows(df_all, df)
# Pause for 1 second
Sys.sleep(1)
}
if(w==1){
result_list[[indicador_atual]] <- df_all
}
else{
result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
}
}
return(result_list)
}
return(result_list)
}
ine.get(indicador,largest,obs_back,result_list)
runApp()
runApp()
runApp()
result_list <- list()
largest <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
indicador <- "0010247"
obs_back <- 2
result_list <- list()
largest_area <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
sleep <- function(z){
if (z %% 100 == 0) {
Sys.sleep(5)
z <- 1
}else{
z <- z+1
}
return(z)
}
ine.get <- function(indicadores,largest_area,obs_back,result_list) {
a <- length(indicadores)
dicofre_2013 <- unique(largest_area$dicofre_2013)
municipio_2013 <- unique(largest_area$municipio_2013_cod)
municipio_2002 <- unique(largest_area$municipio_2002_cod)
nuts_3_2013 <- unique(largest_area$nuts3_2013_cod)
nuts_3_2002 <- unique(largest_area$nuts3_2002_cod)
nuts_2_2013 <- unique(largest_area$nuts2_2013_cod)
nuts_1 <- unique(largest_area$nuts1_2013_cod)
counter <- 0
#Existem 2 desagregacoes que estao hard-coded porque sao iguais entre 2013 e 2002
testd <- c("&Dim2=11102&lang=PT",  #Testa a desagregação por freguesias
"&Dim2=16E0111&lang=PT",#Testa a desagregação por municipio 2013
"&Dim2=1610111&lang=PT",#Testa a desagregação por municipio 2002
"&Dim2=16E&lang=PT",    #Testa a desagregação por NUTSIII 2013
"&Dim2=161&lang=PT",    #Testa a desagregação por NUTSIII 2002
"&Dim2=16&lang=PT",     #Testa a desagregação por NUTSII 2013
"&lang=PT"                      #Testa a desagregação por NUTSI ou sem padrão
)
codes_list <- list(dicofre_2013,municipio_2013,municipio_2002,nuts_3_2013,nuts_3_2002,nuts_2_2013,"")
b_list <- list(length(dicofre_2013),length(municipio_2013),length(municipio_2002),length(nuts_3_2013),length(nuts_3_2002),length(nuts_2_2013),1)
agreg_list <- list("Freguesia","Municipio","Municipio","NUTSIII","NUTSIII","NUTSII","Nacional")
desag_v <- c("&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","&Dim2=","")
# geo_ref_df <- list(dicofre_2013,municipio_2013_cod,municipio_2002_cod,nuts3_2013_codnuts3_2002_cod,nuts2_2013_cod,nuts_1)
geo_ref_by_v <- c("dicofre_2013",
"municipio_2013_cod",
"municipio_2002_cod",
"nuts3_2013_cod",
"nuts3_2002_cod",
"nuts2_2013_cod",
"nuts1_2013_cod")
for (i in 1:a) {
#COMECA POR LER O INDICADOR A RETIRAR
indicador_atual <- indicadores[i]
counter <- sleep(counter)
test <- list()
for (k in 1:length(testd)){
counter <- sleep(counter)
test[[k]] <- as.data.frame(fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T",testd[k])))
}
r <- 1
b <- b_list[[1]]
codes <- codes_list[[1]]
agreg <- agreg_list[[1]]
desag <- desag_v[1]
# geo_ref_df <- geo_ref[[1]]
geo_ref_by <- geo_ref_by_v[1]
while("Falso" %in% colnames(test[[r]]$Sucesso)){
r <- r + 1
b <- b_list[[r]]
codes <- codes_list[[r]]
agreg <- agreg_list[[r]]
desag <- desag_v[r]
# geo_ref_df <- geo_ref[[r]]
geo_ref_by <- geo_ref_by_v[r]
}
for (w in 1:b){
counter <- sleep(counter)
result <- fromJSON(paste0("https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=",indicador_atual,"&Dim1=T", desag, codes[w],"&lang=PT"))
dados <- as.data.frame(result$Dados)
colunas_nanos <- colnames(dados)
num_colunas <- length(colunas_nanos)
if(obs_back > num_colunas){
x <-num_colunas
}else{
x <-obs_back
}
# Get column names for years of interest
obs_cols <- as.character(c(colunas_nanos[(num_colunas-x+1):(num_colunas)]))
df_all <- data.frame()
# Loop over years
for (obs in obs_cols) {
# Remove all columns except current year
df <- dados %>%
unnest(!!sym(obs))%>%
select(-any_of(colunas_nanos))%>%
mutate(obs=as.character(obs))%>%
left_join(largest_area, by=c("geocod" = as.character(geo_ref_by)),  multiple = "first" )
# Add data frame to list
df_all <- bind_rows(df_all, df)
# Pause for 1 second
Sys.sleep(1)
}
if(w==1){
result_list[[indicador_atual]] <- df_all
}
else{
result_list[[indicador_atual]] <- bind_rows(result_list[[indicador_atual]], df_all)
}
}
}
return(result_list)
}
ine.get(indicador,largest,obs_back,result_list)
result_list <- ine.get(indicador,largest,obs_back,result_list)
View(result_list)
runApp()
largest <- geolinkage_aces %>%
filter(aces_2022=="ACES Baixo Mondego")
indicador <- "0008614"
obs_back <- 2
result_list <- ine.get(indicador,largest,obs_back,result_list)
View(result_list)
runApp()
runApp()
runApp()
runApp()
runApp()
items <- names(result_list)
items <- names(result_list)
names(result_list)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
geolinkage_aces <- read_csv("datasets/geolinkage_aces_2022.csv", col_types = cols(.default = "c"), locale = locale("pt"))
library(shiny)
library(shinyWidgets)
library(tidyverse)
library(janitor)
library(readxl)
library(jsonlite)
library(DT)
library(shinyjs)
geolinkage_aces <- read_csv("datasets/geolinkage_aces_2022.csv", col_types = cols(.default = "c"), locale = locale("pt"))
geo_ref_df <- list(geolinkage_aces,
geolinkage_aces[2:20],
geolinkage_aces[2:20],
geolinkage_aces[c(7:20)],
geolinkage_aces[c(7:20)],
geolinkage_aces[c(10:15,19,20)],
geolinkage_aces[c(12:15)])
View(geo_ref_df)
View(geo_ref_df)
runApp('INE_API')
shiny::runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
shiny::runApp('INE_API')
runApp('INE_API')
Indicadores <-
read_excel("datasets/Indicadores.xlsx",
skip = 14)%>%
clean_names()%>%
filter(disponivel_no_portal== "Sim")%>%
distinct(designacao, .keep_all = TRUE)
View(Indicadores)
Indicadores <-
read_excel("datasets/Indicadores.xlsx",
skip = 14)%>%
clean_names()%>%
filter(disponivel_no_portal== "Sim")%>%
distinct(designacao, .keep_all = TRUE)
runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
# install.packages("shinyWidgets")
install.packages("fuzzyjoin")
runApp('INE_API')
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
# install.packages("shinyWidgets")
# install.packages("fuzzyjoin")
# install.packages("DT")
# install.packages("shinyjs")
# install.packages('rsconnect')
install.packages('stringdist')
library(stringdist)
fuzzy_match <- function(x, y) {
# Compute the Levenshtein distance between x and y
dist <- stringdist(x, y, method = "lv")
# Return TRUE if the distance is less than or equal to 2, else FALSE
return(dist <= 3)
}
runApp('INE_API')
runApp('INE_API')
runApp('INE_API')
#install.packages('jsonlite', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(jsonlite)
#install.packages("tidyverse", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(tidyverse)
locale("pt")
# install.packages("readxl", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(readxl)
# install.packages("data.table")
library(data.table)
# install.packages("shiny")
library(shiny)
#install.packages('jsonlite', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(jsonlite)
#install.packages("tidyverse", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(tidyverse)
locale("pt")
# install.packages("readxl", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(readxl)
# install.packages("data.table")
library(data.table)
# install.packages("shiny")
library(shiny)
setwd("C:/Users/jdrdionisio/Desktop/RProjects/Projects/INE/INE_API/")
geolinkage_path <- "datasets/geolinkage_aces_2022.csv"
geolinkage_aces <- read_csv(geolinkage_path,col_types = cols(.default = "c"))
colnames(geolinkage_aces)
largest <- geolinkage_aces %>%
filter(aces_2022=="Estrangeiro")
View(largest)
sleep <- function(z){
if (z %% 100 == 0) {
Sys.sleep(5)
z <- 1
}else{
z <- z+1
}
return(z)
}
runApp('INE_API')
